@incollection{DEPAMPHILIS2019471,
title = "Chapter 17 - Alternative Exit and Restructuring Strategies: Bankruptcy, Reorganization, and Liquidation",
editor = "Donald M. DePamphilis",
booktitle = "Mergers, Acquisitions, and Other Restructuring Activities (Tenth Edition)",
publisher = "Academic Press",
edition = "Tenth Edition",
pages = "471 - 491",
year = "2019",
isbn = "978-0-12-815075-7",
doi = "https://doi.org/10.1016/B978-0-12-815075-7.00017-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780128150757000176",
author = "Donald M. DePamphilis",
keywords = "Corporate bankruptcy, Reorganization, Corporate liquidation, Chapter 11, Chapter 7, Chapter 15, Bankruptcy prediction models, Business failure, Voluntary settlements, Section 363 sales, Prepackaged bankruptcies, Deal structuring, Form of payment, Form of acquisition, Political and economic risks, Segmented markets, Tax rates, Corporate inversions, Debt for equity swaps, Hedge funds, Private equity funds, Financial distress, Out of court settlements, Involuntary settlements, Voluntary liquidation, Involuntary liquidation, Financial distress, Compositions, Extensions, Default prediction, Bankruptcy prediction models, Default prediction models, Default, Bankruptcy, Bankruptcy filing",
abstract = "The focus of this chapter is on bankruptcy and liquidation as alternative restructuring or exit strategies for failing firms, on the characteristics of such firms, and the bankruptcy process. This chapter discusses in detail the major motivations for bankruptcy and the conditions under which a firm is considered to be bankrupt. Bankruptcy enables a failing firm to reorganize, while protected from its creditors, or to cease operation by selling its assets to satisfy all or a portion of the firm’s outstanding debt. How reorganization and liquidation take place both inside and outside the protection of the bankruptcy court are examined in detail, as are Section 363 sales, prepackaged bankruptcy, and cross-border bankruptcy. Common tactics, such as debt for equity swaps, compositions, and extensions, used by debtor firms to negotiate with creditors and the circumstances in which they are used are analyzed. This chapter also discusses the advantages and disadvantages of strategic options for failing firms ranging from merging with another firm to reaching an out-of-court voluntary settlement to voluntary and involuntary liquidations. The chapter also describes the increasing role of hedge funds in the bankruptcy process. The current state of bankruptcy prediction models and their limitations as well as the results of recent empirical studies of the performance of firms experiencing financial distress also are addressed."
}
@article{2020450,
title = "Abstracts",
journal = "Fuel and Energy Abstracts",
volume = "61",
number = "5",
pages = "450 - 541",
year = "2020",
issn = "0140-6701",
doi = "https://doi.org/10.1016/j.fueleneab.2020.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0140670120300266"
}
@article{2013106,
title = "Abstracts",
journal = "Fuel and Energy Abstracts",
volume = "54",
number = "2",
pages = "106 - 202",
year = "2013",
issn = "0140-6701",
doi = "https://doi.org/10.1016/j.fueleneab.2013.01.002",
url = "http://www.sciencedirect.com/science/article/pii/S0140670113000039"
}
@article{AHAD20161,
title = "Neural networks in wireless networks: Techniques, applications and guidelines",
journal = "Journal of Network and Computer Applications",
volume = "68",
pages = "1 - 27",
year = "2016",
issn = "1084-8045",
doi = "https://doi.org/10.1016/j.jnca.2016.04.006",
url = "http://www.sciencedirect.com/science/article/pii/S1084804516300492",
author = "Nauman Ahad and Junaid Qadir and Nasir Ahsan",
keywords = "Wireless networks, Neural networks, Computational intelligence, Artificial intelligence",
abstract = "The design of modern wireless networks, which involves decision making and parameter optimization, is quite challenging due to the highly dynamic, and often unknown, environmental conditions that characterize wireless networks. There is a common trend in modern networks to incorporate artificial intelligence (AI) techniques to cope with this design complexity. While a number of AI techniques have been profitably employed in the wireless networks community, the well-established AI framework of neural networks (NNs), well known for their remarkable generality and versatility, has been applied in a wide variety of settings in wireless networks. In particular, NNs are especially popular for tasks involving classification, learning, or optimization. In this paper, we provide both an exposition of common NN models and a comprehensive survey of the applications of NNs in wireless networks. We also identify pitfalls and challenges of implementing NNs especially when we consider alternative AI models and techniques. While various surveys on NNs exist in the literature, our paper is the first paper, to the best of our knowledge, which focuses on the applications of NNs in wireless networks."
}
@article{2020334,
title = "Abstracts",
journal = "Fuel and Energy Abstracts",
volume = "61",
number = "4",
pages = "334 - 433",
year = "2020",
issn = "0140-6701",
doi = "https://doi.org/10.1016/j.fueleneab.2020.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0140670120300187"
}
@book{bidgoli_encyclopedia_2002,
	address = {Amsterdam ; Boston},
	edition = {1st Edition},
	title = {Encyclopedia of {Information} {Systems}},
	isbn = {978-0-12-227240-0},
	abstract = {The Encyclopedia of Information Systems provides essential answers to questions increasingly asked by people in all walks of life. People can no longer claim that information about computer viruses, for example, is unimportant to their work, or that advances in speech recognition and encryption will leave them unaffected. The Encyclopedia is therefore more useful than one might suspect to people well beyond the walls of information systems departments. Offering both general and technical information about major elements, issues, opinions, and key studies, as well as cross-references to related subjects, it captures the dynamic growth and complexity unique to our era.},
	language = {English},
	publisher = {Academic Press},
	editor = {Bidgoli, Hossein},
	month = aug,
	year = {2002}
}

@incollection{KOTU201563,
title = "Chapter 4 - Classification",
editor = "Vijay Kotu and Bala Deshpande",
booktitle = "Predictive Analytics and Data Mining",
publisher = "Morgan Kaufmann",
address = "Boston",
pages = "63 - 163",
year = "2015",
isbn = "978-0-12-801460-8",
doi = "https://doi.org/10.1016/B978-0-12-801460-8.00004-5",
url = "http://www.sciencedirect.com/science/article/pii/B9780128014608000045",
author = "Vijay Kotu and Bala Deshpande",
keywords = "Classification, decision trees, rule induction, k-nearest neighbors, naïve Bayesian, artificial neural networks, support vector machines, ensemble, bagging, boosting, random forests",
abstract = "In classification or class prediction, we try to use the information from the predictors or independent variables to sort the data samples into two or more distinct classes or buckets. Classification is the most widely used data mining task in business. There are several ways to build classification models. In this chapter, we will discuss and show the implementation of six of the most commonly used classification algorithms: decision trees, rule induction, k-nearest neighbors, naïve Bayesian, artificial neural networks, and support vector machines. We conclude this chapter with building ensemble classification models and a discussion on bagging, boosting, and random forests."
}
@article{SHARMA2015243,
title = "Contextual motivation in physical activity by means of association rule mining",
journal = "Egyptian Informatics Journal",
volume = "16",
number = "3",
pages = "243 - 251",
year = "2015",
issn = "1110-8665",
doi = "https://doi.org/10.1016/j.eij.2015.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S1110866515000328",
author = "Sugam Sharma and Udoyara Sunday Tim and Marinelle Payton and Hari Cohly and Shashi Gadia and Johnny Wong and Sudharshanam Karakala",
keywords = "Association rule mining, Physical activity, Regularity",
abstract = "The primary thrust of this work is to demonstrate the applicability of association rule mining in public health domain, focusing on physical activity and exercising. In this paper, the concept of association rule mining is shown assisting to promote the physical exercise as regular human activity. Specifically, similar to the prototypical example of association rule mining, market basket analysis, our proposed novel approach considers two events – exercise (sporadic) and sleep (regular) as the two items of the frequent set; and associating the former, exercise event, with latter, the daily occurring activity sleep at night, helps strengthening the frequency of the exercise patterns. The regularity can further be enhanced, if the exercising instruments are kept in the vicinity of the bed and are within easy reach."
}
@incollection{KOTU201965,
title = "Chapter 4 - Classification",
editor = "Vijay Kotu and Bala Deshpande",
booktitle = "Data Science (Second Edition)",
publisher = "Morgan Kaufmann",
edition = "Second Edition",
pages = "65 - 163",
year = "2019",
isbn = "978-0-12-814761-0",
doi = "https://doi.org/10.1016/B978-0-12-814761-0.00004-6",
url = "http://www.sciencedirect.com/science/article/pii/B9780128147610000046",
author = "Vijay Kotu and Bala Deshpande",
keywords = "Classification, decision trees, rule induction, -nearest neighbors, naïve Bayesian, artificial neural networks, support vector machines, ensemble, bagging, boosting, random forests",
abstract = "In classification or class prediction, it’s best to try to use the information from the predictors or independent variables to sort a data sample into two or more distinct classes or buckets. Classification is the most widely used data science task in business. There are several ways to build classification models. In this chapter, six of the most commonly used classification algorithms will be discussed and demonstrated: decision trees, rule induction, k-nearest neighbors (k-NNs), naïve Bayesian, artificial neural networks, and support vector machines. This chapter is concluded by building ensemble classification models and a discussion on bagging, boosting, and random forests."
}
@article{REHMAN2019171,
title = "Unsupervised pre-trained filter learning approach for efficient convolution neural network",
journal = "Neurocomputing",
volume = "365",
pages = "171 - 190",
year = "2019",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2019.06.084",
url = "http://www.sciencedirect.com/science/article/pii/S0925231219309981",
author = "Sadaqat ur Rehman and Shanshan Tu and Muhammad Waqas and Yongfeng Huang and Obaid ur Rehman and Basharat Ahmad and Salman Ahmad",
keywords = "Convolution neural networks, ConvNet application, ConvNet optimization, Learning methodologies",
abstract = "The concept of Convolution Neural Network (ConvNet or CNN) is evaluated from the animal visual cortex. Since humans can learn through experience, similarly, ConvNet changes its weight accordingly to accomplish the desired output through backpropagation. In this paper, we provide a comprehensive survey of the relationship between ConvNet with different pre-trained learning methodologies and its optimization effects. These hybrid networks further develop the state-of-the-art algorithms in recognition, classification, and detection of images, speeches, texts, and videos. Furthermore, some task-specific applications of ConvNet have been introduced in computer vision. To validate the survey, we also perform some experiments on a public face and skin detection dataset to provide an authentic solution. The experimental results on the benchmark dataset highlight the merit of efficient pre-trained learning algorithms for optimized ConvNet. To motivate the follow-up research, we identify open problems and present future directions with regards to optimized ConvNet system design parameters and unsupervised learning."
}
@article{CASTELL2018739,
title = "The future decisions of RoboJudge HHJ Arthur Ian Blockchain: Dread, delight or derision?,",
journal = "Computer Law & Security Review",
volume = "34",
number = "4",
pages = "739 - 753",
year = "2018",
issn = "0267-3649",
doi = "https://doi.org/10.1016/j.clsr.2018.05.011",
url = "http://www.sciencedirect.com/science/article/pii/S026736491830195X",
author = "Stephen Castell",
keywords = "Intelligence, Blockchain, Robot, Ethic, Algorithm, Crypto",
abstract = "Steve Saxby's prescient founding of CLSR, two hundred issues ago, encouraged and resonated with my own digital visionary thinking and professional activity in the evolving field of ICT and the Law. From Infolex, the UK's first commercially-available computer-assisted legal information retrieval service, and my APPEAL Report (on the admissibility of computer evidence in court and the legal reliability/security of IT systems), via my Forensic Systems Analysis expert methodology, to the nascent CryptoBlockTV, Steve's scholarly foresight in promoting adventurous exploration of ‘digilaw’ high-ground topics and issues has presented me with opportunities to generate a stream of prescient material, for which I am immensely grateful. And what is beyond prescient today is that the Coming of the Robots is unstoppable. The Artificial Intelligence (AI) Age is upon us; RoboJudge has all but already arrived. While many are concerned about defining and developing Machine Ethics, Castell's Second Dictum: “You cannot construct an algorithm that will reliably decide whether or not any algorithm is ethical” reveals that this is a futile exercise. Algorithms are also pivotal to the current mania for Crypto-Algorithmic Blockchain Technology Initial Coin Offerings (ICOs), with a ‘Crypto Tribe’ of Millennials relentlessly raising billions in real money thereby, to the extent that I have dubbed Crypto the Millennials’ Rock'n’Roll. The seasoned ICT expert professional however bears in mind that there are as yet no ISO standards for blockchain, and there is far more to creating and delivering a complete quality-assured system than just the blockchain component. Furthermore, the legal status of cryptocurrency, smart contract and distributed ledger technology is not clear or uncontentious – and there is already ICO litigation on foot. Nevertheless, taking my limerick-writing Castell GhostWriteBot’s advice, it is perhaps time for my own asset-linked ICO, to launch my CapChere.com concept designed to reboot Capitalism and achieve ubiquitous universal share and wealth ownership. Look out for Castell GhostWriteBot’s account (with or without limericks) of how I fared, in the 400th issue of CLSR."
}
@incollection{LUCA2015563,
title = "Chapter 12 - User-Generated Content and Social Media",
editor = "Simon P. Anderson and Joel Waldfogel and David Strömberg",
series = "Handbook of Media Economics",
publisher = "North-Holland",
volume = "1",
pages = "563 - 592",
year = "2015",
booktitle = "Handbook of Media Economics",
issn = "2213-6630",
doi = "https://doi.org/10.1016/B978-0-444-63685-0.00012-7",
url = "http://www.sciencedirect.com/science/article/pii/B9780444636850000127",
author = "Michael Luca",
keywords = "User-generated content, Social media, Economics of information, Design economics, D8, L1, L86",
abstract = "This chapter documents what economists have learned about user-generated content (UGC) and social media. A growing body of evidence suggests that UGC on platforms ranging from Yelp to Facebook has a large causal impact on economic and social outcomes ranging from restaurant decisions to voting behavior. These findings often leverage unique datasets and methods ranging from regression discontinuity to field experiments, and researchers often work directly with the companies they study. I then survey the factors that influence the quality of UGC. Quality is influenced by factors including promotional content, peer effects between contributors, biases of contributors, and self-selection into the decision to contribute. Non-pecuniary incentives, such as “badges” and social status on a platform, are often used to encourage and steer contributions. I then discuss other issues including business models, network effects, and privacy. Throughout the chapter, I discuss open questions in this area."
}
@article{TAYLOR20171039,
title = "The next stage of U.S. communications policy: The emerging embedded infosphere",
journal = "Telecommunications Policy",
volume = "41",
number = "10",
pages = "1039 - 1055",
year = "2017",
note = "Celebrating 40 Years of Telecommunications Policy – A Retrospective and Prospective View",
issn = "0308-5961",
doi = "https://doi.org/10.1016/j.telpol.2016.11.007",
url = "http://www.sciencedirect.com/science/article/pii/S0308596116302488",
author = "Richard D. Taylor",
keywords = "Internet of Things, Big data, Intercloud, Artificial Intelligence, DIGIT Act, ICANN, Embedded Infosphere",
abstract = "The United States needs to reimagine the basic principles of its telecommunications and information policy to fit an emerging society in which networking and intelligence are embedded into an increasing number of everyday things which constantly monitor and measure our lives. This emerging environment is an always-on, ubiquitous, integrated system comprised of the Internet of Things, Big Data, Artificial Intelligence/Intelligent Systems and the Intercloud, which act together as a single system, referred to here as the “Embedded Infosphere” (EI). This development is driving the latest stage – the third – in the evolution of U.S. communications policy. Each of the components of the EI presents unique challenges, but the greater concern is all of them acting in concert. These developments bring into focus many topics that have been outside the traditional communications policy envelope, and exceed the portfolios of existing agencies and institutions. This article envisions a new “EI policy space,” grounded in established societal values, and built on the experience of the previous stages. There are appropriate policy responses to each of the challenges, but these responses need to be seen in a holistic perspective, as they are all interconnected. Many of the issues such as privacy, security, consumer protection, and data stewardship are common across several elements. The larger goal is to establish a framework for an integrated policy structure which can address unpredictable emergent conditions, while allowing markets to flourish without unduly burdensome regulations, restrictions or uncertainties. This articles suggests a high-level analytical framework of criteria against which proposed EI policies can be measured. While there may be no “perfect” policies, some may be better (or worse) than others. It also offers a political process designed to incorporate the concept of the EI into national policy thinking. This approach should be implemented through a series of steps and should provide flexibility for development. The initial step is a process by which the EI can be acknowledged, its development analyzed, and the national interests institutionalized. The U.S. Senate has already initiated this process with the pending “DIGIT” Act, designed to bring together the core federal stakeholders and open a policy discourse which will be expanded over time to other key stakeholders. This should lead to the development of a national EI strategy. Since the EI is progressively global, the article suggests how both the normative and regulatory dimensions can be approached in the global context. It raises the possibility of a restructured ICANN “Empowered Community” as a possible venue for developing policies and recommendations in this area. It notes that since global unanimity is unlikely, non-governmental regimes will likely develop to address the unresolved policy interstices."
}
@article{20051,
title = "Front cover and table of contents",
journal = "IFAC Proceedings Volumes",
volume = "38",
number = "1",
pages = "1 - 3456",
year = "2005",
note = "16th IFAC World Congress",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20050703-6-CZ-1902.00001",
url = "http://www.sciencedirect.com/science/article/pii/S147466701636013X"
}
@book{witten_data_2011,
	address = {Burlington, MA},
	edition = {3rd Edition},
	title = {Data {Mining}: {Practical} {Machine} {Learning} {Tools} and {Techniques}},
	isbn = {978-0-12-374856-0},
	shorttitle = {Data {Mining}},
	abstract = {Data Mining: Practical Machine Learning Tools and Techniques, Third Edition, offers a thorough grounding in machine learning concepts as well as practical advice on applying machine learning tools and techniques in real-world data mining situations. This highly anticipated third edition of the most acclaimed work on data mining and machine learning will teach you everything you need to know about preparing inputs, interpreting outputs, evaluating results, and the algorithmic methods at the heart of successful data mining. Thorough updates reflect the technical changes and modernizations that have taken place in the field since the last edition, including new material on Data Transformations, Ensemble Learning, Massive Data Sets, Multi-instance Learning, plus a new version of the popular Weka machine learning software developed by the authors. Witten, Frank, and Hall include both tried-and-true techniques of today as well as methods at the leading edge of contemporary research.  The book is targeted at information systems practitioners, programmers, consultants, developers, information technology managers, specification writers, data analysts, data modelers, database R\&D professionals, data warehouse engineers, data mining professionals. The book will also be useful for professors and students of upper-level undergraduate and graduate-level data mining and machine learning courses who want to incorporate data mining as part of their data management knowledge base and expertise.},
	language = {English},
	publisher = {Morgan Kaufmann},
	author = {Witten, Ian H. and Frank, Eibe and Hall, Mark A.},
	month = jan,
	year = {2011}
}

@incollection{CHILDS201975,
title = "3 - Ideation",
editor = "Peter R.N. Childs",
booktitle = "Mechanical Design Engineering Handbook (Second Edition)",
publisher = "Butterworth-Heinemann",
edition = "Second Edition",
pages = "75 - 144",
year = "2019",
isbn = "978-0-08-102367-9",
doi = "https://doi.org/10.1016/B978-0-08-102367-9.00003-2",
url = "http://www.sciencedirect.com/science/article/pii/B9780081023679000032",
author = "Peter R.N. Childs",
keywords = "Analysis, Brainstorming, Creative, Creativity, Engine, Evaluation, Morphological, Problem, Solving, Tools, TRIZ",
abstract = "Engineering design relies upon the generation of alternative ideas and their effective evaluation to ensure that attention is directed in a worthwhile manner. This chapter explores a number of creativity tools that are widely used for the generation of ideas including flip chart; post-it notes; alphabet and grid brainstorming; the creative problem solving process, also known as CPS; morphological analysis, a matrix combinational creativity tool; and TRIZ the theory of inventive problem solving. The chapter includes consideration of group dynamics and the evaluation of ideas as well as approaches for encouraging the realisation of value from creativity through innovation."
}
@article{2009i,
title = "Technical Program",
journal = "IFAC Proceedings Volumes",
volume = "42",
number = "8",
pages = "i - lxxi",
year = "2009",
note = "7th IFAC Symposium on Fault Detection, Supervision and Safety of Technical Processes",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20090630-4-ES-2003.90003",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016357433"
}
@incollection{200483,
title = "Subject Index",
editor = "Neil J. Smelser and Paul B. Baltes",
booktitle = "International Encyclopedia of the Social & Behavioral Sciences",
publisher = "Pergamon",
address = "Oxford",
pages = "83 - 899",
year = "2004",
isbn = "978-0-08-043076-8",
doi = "https://doi.org/10.1016/B0-08-043076-7/99109-5",
url = "http://www.sciencedirect.com/science/article/pii/B0080430767991095"
}
@article{GROUMPOS2016180,
title = "Deep Learning vs. Wise Learning: A Critical and Challenging Overview",
journal = "IFAC-PapersOnLine",
volume = "49",
number = "29",
pages = "180 - 189",
year = "2016",
note = "17th IFAC Conference on International Stability, Technology and Culture TECIS 2016",
issn = "2405-8963",
doi = "https://doi.org/10.1016/j.ifacol.2016.11.099",
url = "http://www.sciencedirect.com/science/article/pii/S240589631632537X",
author = "Peter P. Groumpos",
keywords = "Learning, Knowledge, Wisdom, Deep Learning, Wise Learning, Fuzzy Cognitive Maps",
abstract = "Abstract:
Learning is the most important thing that living creatures do. An organism cannot properly animate itself without first learning how to. Knowledge is the basis for all natural and human made systems. Using knowledge to model and control a complex dynamic system (CDS) is considered. Wisdom is carefully reviewed and related to knowledge. Deep Learning (DL) and Wise Learning (WL) are presented and analyzed as two approaches to address the challenging problem of modelling and controlling CDS. Strong and weak issues of both methods are discussed. Future research directions are provided."
}
@incollection{HALEVI200159,
title = "5 - 110 manufacturing methods",
editor = "Gideon Halevi",
booktitle = "Handbook of Production Management Methods",
publisher = "Butterworth-Heinemann",
address = "Oxford",
pages = "59 - 310",
year = "2001",
isbn = "978-0-7506-5088-5",
doi = "https://doi.org/10.1016/B978-075065088-5/50005-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780750650885500054",
author = "Gideon Halevi",
abstract = "Publisher Summary
This chapter briefly describes each of the 110 manufacturing methods, such as agent-driven approach, activity-based costing (ABC), agile manufacturing, and so on. Activity-based costing is an information system that maintains and processes data on a firm's activities and products/services. It identifies the activities performed, traces costs to these activities, and then uses various cost drivers to trace the cost of activities to the final products/services. Agent-driven manufacturing systems are designed to solve shop-floor-control problems in manufacturing systems. Agile manufacturing can be defined as the capability of reacting quickly to changing markets, to produce high quality products, to reduce lead times, and to provide superior service. These are achieved by improving enterprise communications among all disciplines engaged in the manufacturing process."
}
@article{2017iii,
title = "Contents",
journal = "Procedia Computer Science",
volume = "112",
pages = "iii - xvii",
year = "2017",
note = "Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France",
issn = "1877-0509",
doi = "https://doi.org/10.1016/S1877-0509(17)31783-0",
url = "http://www.sciencedirect.com/science/article/pii/S1877050917317830"
}
@article{SEIFERT2004461,
title = "Data mining and the search for security: Challenges for connecting the dots and databases",
journal = "Government Information Quarterly",
volume = "21",
number = "4",
pages = "461 - 480",
year = "2004",
issn = "0740-624X",
doi = "https://doi.org/10.1016/j.giq.2004.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0740624X04000590",
author = "Jeffrey W. Seifert",
abstract = "Data mining is emerging as one of the key features of many homeland security initiatives. Often used as a means for detecting fraud, assessing risk, and product retailing, data mining involves the use of data analysis tools to discover previously unknown, valid patterns and relationships in large data sets. In the context of homeland security, data mining is often viewed as a potential means to identify terrorist activities, such as money transfers and communications, and to identify and track individual terrorists themselves, such as through travel and immigration records. However, compared to earlier uses of data mining by government, some of the homeland security data mining applications represent a significant expansion in the quantity and scope of data to be analyzed. Three of the higher profile initiatives include the now defunct Terrorism Information Awareness (TIA) project, the recently canceled Computer-Assisted Passenger Prescreening System II (CAPPS II), and the Multistate Anti-Terrorism Information Exchange (MATRIX) pilot project. This article examines the evolving nature of data mining for homeland security purposes, the limitations of data mining, and some of the issues raised by its expanding use, including data quality, interoperability, mission creep, and privacy."
}
@article{SHARMA201663,
title = "Expanded cloud plumes hiding Big Data ecosystem",
journal = "Future Generation Computer Systems",
volume = "59",
pages = "63 - 92",
year = "2016",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2016.01.003",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X16000054",
author = "Sugam Sharma",
keywords = "Cloud, Big Data, Smart Data and Lakes, IoT, XCLOUDX, as-a-Service",
abstract = "Today, a paradigm shift is being observed in science, where the focus is gradually shifting away from operation to data, which is greatly influencing the decision making also. The data is being inundated proactively from several sources in various forms; especially social media and in modern data science vocabulary is being recognized as Big Data. Today, Big Data is permeating through the bigger aspect of human life for scientific and commercial dependencies, especially for massive scale data analytics of beyond the exabyte magnitude. As the footprint of Big Data applications is continuously expanding, the reliability on cloud environments is also increasing to obtain appropriate, robust and affordable services to deal with Big Data challenges. Cloud computing avoids any need to locally maintain the overly scaled computing infrastructure that include not only dedicated space, but the expensive hardware and software also. Several data models to process Big Data are already developed and a number of such models are still emerging, potentially relying on heterogeneous underlying storage technologies, including cloud computing. In this paper, we investigate the growing role of cloud computing in Big Data ecosystem. Also, we propose a novel XCLOUDX {XCloudX, X…X}classification to zoom in to gauge the intuitiveness of the scientific name of the cloud-assisted NoSQL Big Data models and analyze whether XCloudX always uses cloud computing underneath or vice versa. XCloudX symbolizes those NoSQL Big Data models that embody the term “cloud” in their name, where X is any alphanumeric variable. The discussion is strengthen by a set of important case studies. Furthermore, we study the emergence of as-a-Service era, motivated by cloud computing drive and explore the new members beyond traditional cloud computing stack, developed in the past couple of years."
}
@article{BILAL2020113194,
title = "Big Data with deep learning for benchmarking profitability performance in project tendering",
journal = "Expert Systems with Applications",
volume = "147",
pages = "113194",
year = "2020",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2020.113194",
url = "http://www.sciencedirect.com/science/article/pii/S0957417420300208",
author = "Muhammad Bilal and Lukumon O. Oyedele",
keywords = "Big Data, Project tendering, Text mining, Deep learning, Benchmarking KPIs",
abstract = "A reliable benchmarking system is crucial for the contractors to evaluate the profitability performance of project tenders. Existing benchmarks are ineffective in the tender evaluation task for three reasons. Firstly, these benchmarks are mostly based on the profit margins as the only key performance indicator (KPI) while there are other KPIs fit to drive the evaluation process. Secondly, these benchmarks don’t take project context into account, thereby restricts their predictive accuracy. And finally, these benchmarks are obtained from small subsets of data, making it hard to generalise. As a result, estimators cannot probe into tenders to judge the strengths and weaknesses of their bids. This advancement is critical for not only choosing more lucrative opportunities but also driving negotiations during the tendering process. This study aims to develop a benchmarking system for tender evaluation using Big Data of 1.2 terabytes, comprising 5.7 million cells. A holistic list of seventeen (17) KPIs is identified from the email data using Text Mining approaches. Besides, eight (8) key project attributes are chosen for ensuring context-aware benchmarking using Focused Group Interviews (FGIs). At the crux of this work lies the proposition of a deep ensemble learner based on the decomposition-integration methodology. In the decomposition stage, the model predicts several attribute-specific benchmarks for each KPI using our proposed context-aware algorithm. In the integration stage, deep neural network-based learners are trained to generate final project-sensitive KPI benchmark. The learner is deployed in the Spring tool to support the tender evaluation of power infrastructure projects. A tender of 60km underground cabling project is evaluated using the proposed learner. The system spontaneously identified KPIs in the tender that require further attention to achieve greater profitability performance."
}
@article{KAUSHAL2018423,
title = "Soft Computing based object detection and tracking approaches: State-of-the-Art survey",
journal = "Applied Soft Computing",
volume = "70",
pages = "423 - 464",
year = "2018",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2018.05.023",
url = "http://www.sciencedirect.com/science/article/pii/S1568494618302965",
author = "Manisha Kaushal and Baljit S. Khehra and Akashdeep Sharma",
keywords = "Soft computing, Object detection and tracking, Neural network and deep learning, Fuzzy logic, Evolutionary algorithms",
abstract = "In recent years, analysis and interpretation of video sequences to detect and track objects of interest had become an active research field in computer vision and image processing. Detection and tracking includes extraction of moving object from frames and continuous tracking it thereafter forming persistent object trajectories over time. There are some really smart techniques proposed by researchers for efficient and robust detection or tracking of objects in videos. A comprehensive coverage of such innovative techniques for which solutions have been motivated by theories of soft computing approaches is proposed. The main objective of this research investigation is to study and highlight efforts of researchers who had conducted some brilliant work on soft computing based detection and tracking approaches in video sequence. The study is novel as it traces rise of soft computing methods in field of object detection and tracking in videos which has been neglected over the years. The survey is compilation of studies on neural network, deep learning, fuzzy logic, evolutionary algorithms, hybrid and recent innovative approaches that have been applied to field of detection and tracking. The paper also highlights benchmark datasets available to researchers for experimentation and validation of their own algorithms. Major research challenges in the field of detection and tracking along with some recommendations are also provided. The paper provides number of analyses to guide future directions of research and advocates for more applications of soft computing approaches for object detection and tracking approaches in videos. The paper is targeted at young researchers who will like to see it as platform for introduction to a mature and relatively complex field. The study will be helpful in appropriate use of an existing method for systematically designing a new approach or improving performance of existing approaches."
}
@article{20162,
title = "Abstracts",
journal = "Fuel and Energy Abstracts",
volume = "57",
number = "1",
pages = "2 - 78",
year = "2016",
issn = "0140-6701",
doi = "https://doi.org/10.1016/j.fueleneab.2015.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S0140670115005500"
}
