@inproceedings{10.1145/3195106.3195178,
author = {Cui, Shaoying and Ding, Ning},
title = {Construction of a Bank Customer Data Warehouse and an Application of Data Mining},
year = {2018},
isbn = {9781450363532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195106.3195178},
doi = {10.1145/3195106.3195178},
abstract = {In this era of strong competition, data mining can provide effective support to bank operators in their effort to analyze and forecast the real needs of their customers. Applying bank data mining results to the actual business enables banks to develop products that not only meet customer needs but also deliver maximum bank profitability. In this paper, a data mining model for bank customers is established, and after extraction and transformation, the data are loaded into a data warehouse specifically built for that purpose. Using the data mining platform, we conduct multidimensional analysis of the customer information to uncover characteristics of their preferences. The goal of this research is to help facilitate new ideas and methods for the analysis and prediction of bank customer data.},
booktitle = {Proceedings of the 2018 10th International Conference on Machine Learning and Computing},
pages = {161–166},
numpages = {6},
keywords = {Bank customer information, data mining, data warehouse, multidimensional data analysis},
location = {Macau, China},
series = {ICMLC 2018}
}

@inproceedings{10.1145/3009977.3010073,
author = {I, Shahid K and Chaudhury, Santanu},
title = {Scalable Clustering and Applications},
year = {2016},
isbn = {9781450347532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3009977.3010073},
doi = {10.1145/3009977.3010073},
abstract = {Large scale machine learning is becoming an active research area recently. Most of the existing clustering algorithms cannot handle big data due to its high time and space complexity. Among the clustering algorithms, eigen vector based clustering, such as Spectral clustering, shows very good accuracy, but it has cubic time complexity. There are various methods proposed to reduce the time and space complexity for eigen decomposition such as Nystr\"{o}m method, Lanc-zos method etc. Nystr\"{o}m method has linear time complexity in terms of number of data points, but has cubic time complexity in terms of number of sampling points. To reduce this, various Rank k approximation methods also proposed, but which are less efficient compare to the normalized spectral clustering. In this paper we propose a two step algorithm for spectral clustering to reduce the time complexity toO(nmk + m2k'), by combining both Nystr\"{o}m and Lanczos method, where k is the number of clusters and k' is the rank k approximation of the sampling matrix (k &lt; k' &lt;&lt; m &lt;&lt; n). It shows very good results, with various data sets, image segmentation problems and churn prediction of a telecommunication data set, even with very low sampling (for 10 Million \texttimes{} 10 Million matrix, sampled only 100 columns) with lesser time, which confirms the validity of the algorithm.},
booktitle = {Proceedings of the Tenth Indian Conference on Computer Vision, Graphics and Image Processing},
articleno = {34},
numpages = {7},
keywords = {large scale machine learning, segmentation and grouping},
location = {Guwahati, Assam, India},
series = {ICVGIP '16}
}

@inproceedings{10.1145/2808797.2808821,
author = {G\"{o}k, Mehmet and \"{O}zyer, Tansel and Jida, Jamal},
title = {A Case Study for the Churn Prediction in Turksat Internet Service Subscription},
year = {2015},
isbn = {9781450338547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808797.2808821},
doi = {10.1145/2808797.2808821},
abstract = {Churn prediction is a customer relationship process that predicts for customers who are at the brink of transferring all the business to competitor. It is predicted by modeling customer behaviors in order to extract patterns. An acquaintance of a customer is more costly than retainment of an existing customer. Churn predictions shed light on members about to leave the service and support promotion activities. These attempts are utilized to avoid subscription cancellation of existing customers. Nowadays, telecommunication companies take churn prediction very serious. They strive for monitoring customers in the business by using various applications in systematic approach. Our study is based on leading internet service providing company, Turksat Satellite Communications and Cable TV Operations Company's customer behavior analysis. It is the leading internet service provider of Turkey operating in telecommunications sector. We have created a two-phase solution utilizing data mining techniques. These are time series clustering and classification techniques.},
booktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015},
pages = {1220–1224},
numpages = {5},
keywords = {Customer relationship management, data mining, time series clustering, hierarchical clustering, recursive partitioning, churn prediction, classification, support vector machines, k-means clustering},
location = {Paris, France},
series = {ASONAM '15}
}

@article{10.1145/2594473.2594475,
author = {Freitas, Alex A.},
title = {Comprehensible Classification Models: A Position Paper},
year = {2014},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/2594473.2594475},
doi = {10.1145/2594473.2594475},
abstract = {The vast majority of the literature evaluates the performance of classification models using only the criterion of predictive accuracy. This paper reviews the case for considering also the comprehensibility (interpretability) of classification models, and discusses the interpretability of five types of classification models, namely decision trees, classification rules, decision tables, nearest neighbors and Bayesian network classifiers. We discuss both interpretability issues which are specific to each of those model types and more generic interpretability issues, namely the drawbacks of using model size as the only criterion to evaluate the comprehensibility of a model, and the use of monotonicity constraints to improve the comprehensibility and acceptance of classification models by users.},
journal = {SIGKDD Explor. Newsl.},
month = mar,
pages = {1–10},
numpages = {10},
keywords = {decision tree, monotonicity constraint, nearest neighbors, Bayesian network classifiers, decision table, rule induction}
}

@article{10.1145/1376815.1376817,
author = {Gupta, Gunjan and Ghosh, Joydeep},
title = {Bregman Bubble Clustering: A Robust Framework for Mining Dense Clusters},
year = {2008},
issue_date = {July 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/1376815.1376817},
doi = {10.1145/1376815.1376817},
abstract = {In classical clustering, each data point is assigned to at least one cluster. However, in many applications only a small subset of the available data is relevant for the problem and the rest needs to be ignored in order to obtain good clusters. Certain nonparametric density-based clustering methods find the most relevant data as multiple dense regions, but such methods are generally limited to low-dimensional data and do not scale well to large, high-dimensional datasets. Also, they use a specific notion of “distance”, typically Euclidean or Mahalanobis distance, which further limits their applicability. On the other hand, the recent One Class Information Bottleneck (OC-IB) method is fast and works on a large class of distortion measures known as Bregman Divergences, but can only find a single dense region. This article presents a broad framework for finding k dense clusters while ignoring the rest of the data. It includes a seeding algorithm that can automatically determine a suitable value for k. When k is forced to 1, our method gives rise to an improved version of OC-IB with optimality guarantees. We provide a generative model that yields the proposed iterative algorithm for finding k dense regions as a special case. Our analysis reveals an interesting and novel connection between the problem of finding dense regions and exponential mixture models; a hard model corresponding to k exponential mixtures with a uniform background results in a set of k dense clusters. The proposed method describes a highly scalable algorithm for finding multiple dense regions that works with any Bregman Divergence, thus extending density based clustering to a variety of non-Euclidean problems not addressable by earlier methods. We present empirical results on three artificial, two microarray and one text dataset to show the relevance and effectiveness of our methods.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jul,
articleno = {8},
numpages = {49},
keywords = {expectation maximization, One Class classification, exponential family, Density-based clustering, Bregman divergences}
}

@article{10.1145/3185045,
author = {Zimbra, David and Abbasi, Ahmed and Zeng, Daniel and Chen, Hsinchun},
title = {The State-of-the-Art in Twitter Sentiment Analysis: A Review and Benchmark Evaluation},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {2158-656X},
url = {https://doi.org/10.1145/3185045},
doi = {10.1145/3185045},
abstract = {Twitter has emerged as a major social media platform and generated great interest from sentiment analysis researchers. Despite this attention, state-of-the-art Twitter sentiment analysis approaches perform relatively poorly with reported classification accuracies often below 70%, adversely impacting applications of the derived sentiment information. In this research, we investigate the unique challenges presented by Twitter sentiment analysis and review the literature to determine how the devised approaches have addressed these challenges. To assess the state-of-the-art in Twitter sentiment analysis, we conduct a benchmark evaluation of 28 top academic and commercial systems in tweet sentiment classification across five distinctive data sets. We perform an error analysis to uncover the causes of commonly occurring classification errors. To further the evaluation, we apply select systems in an event detection case study. Finally, we summarize the key trends and takeaways from the review and benchmark evaluation and provide suggestions to guide the design of the next generation of approaches.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = aug,
articleno = {5},
numpages = {29},
keywords = {social media, benchmark evaluation, twitter, Sentiment analysis, natural language processing, opinion mining, text mining}
}

@proceedings{10.1145/2723372,
title = {SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to SIGMOD 2015 -- officially, the 2015 ACM SIGMOD International Conference on the Management of Data! This year's conference is being held in the beautiful cultural capital of Australia, Melbourne. During the Gold Rush period of the 19th Century, Melbourne was the richest city in the world, and as a result it is filled with many unique neighborhoods and distinctive buildings. In addition to wonderful neighborhoods to explore, the city has great museums and other cultural attractions, as well as a fine multi-cultural atmosphere. For those who would like to explore the outdoors, popular highlights are the Phillip Island Nature Park (90 minutes away), which features wild penguins who return in a parade each day at sunset, and the Great Ocean Road, one of the world's most scenic coastal drives, including the famous towering 12 Apostles.SIGMOD 2015's exciting technical program reflects not only traditional topics, but the database community's role in broader data science and data analytics. The keynote from Laura Haas, "The Power Behind the Throne: Information Integration in the Age of Data-Driven Discovery" highlights the role of database and data integration techniques in the growing field of data science. Jignesh Patel's talk, "From Data to Insights @ Bare Metal Speed," explains how hardware and software need to be co-evolved to support the needs of scalable data analytics. Jennifer Widom, winner of the 2015 ACM-W Athena Lecturer Award for fundamental contributions to computer science, will give her award talk, "Three Favorite Results," on Tuesday. Christopher R\'{e} will lead a panel on "Machine Learning and Databases: The Sound of Things to Come or a Cacophony of Hype?," with participants Divyakant Agrawal, Magdalena Balazinska, Michael Cafarella, Michael Jordan, Tim Kraska, and Raghu Ramakrishnan. Of course, there are also 106 research paper presentations, 4 tutorials, 30 demonstrations, and 18 industrial papers. Papers will be presented both as talks during the research sessions, and as part of plenary Poster Sessions.SIGMOD 2015 is preceded by the PhD Workshop, as well as workshops on leading-edge topics like data analytics (DanaC), databases and the Web (WebDB), exploratory search (ExploreDB), managing and mining spatial data (GeoRich), and graph data (GRADES); the New Researcher Symposium will take place on Wednesday. The banquet will be held in a Melbourne landmark, the Town Hall.As in recent years, we had two submission deadlines for SIGMOD this year, one in August and one in November. The review process was journal-style, with multiple rounds of reviews coordinated by the Group Leaders. We accepted 34 of 137 papers from the first deadline and 72 of 278 from the second deadline. The total acceptance rate was about 25.5%, and we believe that the revision processhas improved the quality of the technical program.},
location = {Melbourne, Victoria, Australia}
}

@inproceedings{10.1145/2487575.2487590,
author = {Nagano, Shouichi and Ichikawa, Yusuke and Takaya, Noriko and Uchiyama, Tadasu and Abe, Makoto},
title = {Nonparametric Hierarchal Bayesian Modeling in Non-Contractual Heterogeneous Survival Data},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487590},
doi = {10.1145/2487575.2487590},
abstract = {An important problem in the non-contractual marketing domain is discovering the customer lifetime and assessing the impact of customer's characteristic variables on the lifetime. Unfortunately, the conventional hierarchical Bayes model cannot discern the impact of customer's characteristic variables for each customer. To overcome this problem, we present a new survival model using a non-parametric Bayes paradigm with MCMC. The assumption of a conventional model, logarithm of purchase rate and dropout rate with linear regression, is extended to include our assumption of the Dirichlet Process Mixture of regression. The extension assumes that each customer belongs probabilistically to different mixtures of regression, thereby permitting us to estimate a different impact of customer characteristic variables for each customer. Our model creates several customer groups to mirror the structure of the target data set.The effectiveness of our proposal is confirmed by a comparison involving a real e-commerce transaction dataset and an artificial dataset; it generally achieves higher predictive performance. In addition, we show that preselecting the actual number of customer groups does not always lead to higher predictive performance.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {668–676},
numpages = {9},
keywords = {model choice, mcmc, non-parametric bayes, crm},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

