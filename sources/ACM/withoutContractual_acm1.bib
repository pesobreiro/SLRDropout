@inproceedings{10.1145/3387168.3387219,
author = {Mohammad, Nurul Izzati and Ismail, Saiful Adli and Kama, Mohd Nazri and Yusop, Othman Mohd and Azmi, Azri},
title = {Customer Churn Prediction In Telecommunication Industry Using Machine Learning Classifiers},
year = {2019},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387168.3387219},
doi = {10.1145/3387168.3387219},
abstract = {Customer churn is one of the main problems in telecommunication industry. This study aims to identify the factors that influence customer churn and develop an effective churn prediction model as well as provide best analysis of data visualization results. The dataset has been collected from Kaggle open data website. The proposed methodology for analysis of churn prediction covers several phases: data pre-processing, analysis, implementing machine learning algorithms, evaluation of the classifiers and choose the best one for prediction. Data preprocessing process involved three major action, which are data cleaning, data transformation and feature selection. Machine learning classifiers was chosen are Logistic Regression, Artificial Neural Network and Random Forest. Then, classifiers were evaluated by using performance measurement which are accuracy, precision, recall and error rate in order to find the best classifier. Based on this study, the output shows that logistic regression outperform compared to artificial neural network and random forest.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {34},
numpages = {7},
keywords = {Customer Churn, Prediction, Machine Learning, Telecommunication Industry},
location = {Vancouver, BC, Canada},
series = {ICVISP 2019}
}

@inproceedings{10.1145/3366030.3366109,
author = {undefinedniegula, Anna and Poniszewska-Mara\'{n}da, Aneta and Popovi\'{c}, Milan},
title = {Study of Machine Learning Methods for Customer Churn Prediction in Telecommunication Company},
year = {2019},
isbn = {9781450371797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366030.3366109},
doi = {10.1145/3366030.3366109},
abstract = {The paper presents the results of investigation which machine learning techniques are most suited for customer churn prediction. Different approaches were compared, starting from the simple K-means method, through decision trees, ending with the artificial neural network. The authors trained the models with each method and predicted whether a customer is going to leave the current telecommunication company.},
booktitle = {Proceedings of the 21st International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {640–644},
numpages = {5},
keywords = {predictive analytics, k-means clustering, decision trees, client churn prediction, machine learning, neural networks},
location = {Munich, Germany},
series = {iiWAS2019}
}

@inproceedings{10.1145/3383972.3384046,
author = {Tang, Qi and Xia, Guoen and Zhang, Xianquan and Li, Yaxiang},
title = {A Feature Interaction Network for Customer Churn Prediction},
year = {2020},
isbn = {9781450376426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383972.3384046},
doi = {10.1145/3383972.3384046},
abstract = {Customer churn prediction is an active research topic for the data mining community and business managers in this rapidly growing society. The ability to detect churn customers precisely is something that every company would wish to achieve. With the great success of DNNs, several churn prediction models based on DNNs are proposed in recent years. However, traditional DNNs cannot learn high-order feature interactions and deal with one-hot vectors well. In this paper, we proposed a feature interaction network (FIN), which aims to enhance the inherent relations of discrete features and learn high-order feature interactions. This network contains two modules: an entity embedding network and a factorization machine network with several sliding windows. From the experiments, it is observed that our proposed model has a better predictive performance than several state-of-the-art models on 4 public datasets.},
booktitle = {Proceedings of the 2020 12th International Conference on Machine Learning and Computing},
pages = {242–248},
numpages = {7},
keywords = {Customer churn, sliding window, entity embedding, data mining, factorization machine, feature interaction},
location = {Shenzhen, China},
series = {ICMLC 2020}
}

@inproceedings{10.1145/3176653.3176731,
author = {Sripawatakul, Phattara and Sutivong, Daricha},
title = {Predicting Customer Churn in Mobile Football Application},
year = {2017},
isbn = {9781450363518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3176653.3176731},
doi = {10.1145/3176653.3176731},
abstract = {Customer churn prediction plays a significant role in various businesses such as telecommunication, banking, and insurance. Accurate churn prediction helps businesses put forward a direct measure toward customers with tendency to leave rather than offering a generic promotion to all. Likewise, mobile application aims not only to acquire new customers but also to retain existing ones. Customer churn prediction in mobile application is a relatively new area, and existing research is limited. This paper proposes a framework for determining, analyzing and predicting customer churn in mobile application.},
booktitle = {Proceedings of the 2017 International Conference on Information Technology},
pages = {366–370},
numpages = {5},
keywords = {Classification, Data Mining, Prediction, Decision Tree, Customer Churn, Mobile Football Application},
location = {Singapore, Singapore},
series = {ICIT 2017}
}

@inproceedings{10.1145/3409073.3409083,
author = {Zhu, Bing and Qian, Cheng and Pan, Xin and Chen, Hao},
title = {A Trajectory-Based Deep Sequential Method for Customer Churn Prediction},
year = {2020},
isbn = {9781450377645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409073.3409083},
doi = {10.1145/3409073.3409083},
abstract = {Customer churn prediction is a pivotal issue in business marketing. Many researches have been pursuing more efficient features and techniques for it. Rapid growth of mobile Internet devices has generated large amounts of customer trajectory data, which contains abundant customer behavior patterns and contributes to many business actions. In this paper we propose a trajectory-based deep sequential method called TR-LSTM for customer churn prediction to mining the customer behavior pattern behind trajectory data. The method extracts three types of trajectory-based features and applied the long short-term memory neural network (LSTM) to conduct sequential modeling. Experimental results on real-world customer trajectory data sets demonstrate that the proposed TR-LSTM obtains better performance than all baseline methods. Our method provides a new tool of churn prediction for both academics and practitioners.},
booktitle = {Proceedings of the 2020 5th International Conference on Machine Learning Technologies},
pages = {114–118},
numpages = {5},
keywords = {trajectory, churn prediction, deep sequential model},
location = {Beijing, China},
series = {ICMLT 2020}
}

@inproceedings{10.1145/2665994.2665997,
author = {Abd-Allah, Marwa N. and Salah, Akram and El-Beltagy, Samhaa R.},
title = {Enhanced Customer Churn Prediction Using Social Network Analysis},
year = {2014},
isbn = {9781450313032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2665994.2665997},
doi = {10.1145/2665994.2665997},
abstract = {There were 6.8 billion estimates for mobile subscriptions worldwide by end of 2013 [11]. As the mobile market gets saturated, it becomes harder for telecom providers to acquire new customers, and makes it essential for them to retain their own. Due to the high competition between different telecom providers and the ability of customers to move from one provider to another, all telecom service providers suffer from customer churn. As a result, churn prediction has become one of the main telecom challenges. The primary goal of churn prediction is to predict a list of potential churners, so that telecom providers can start targeting them by retention campaigns. This work describes work in progress in which we model churn as a dyadic social behavior, where customer churn propagates in the telecom network over strong social ties. We propose a novel method for measuring social tie strength between telecom customers. We then, incorporate strong social ties in an influence propagation model, and apply a machine-learning based prediction model that combines both churn social influence and other traditional churn factors. The goals of our proposed model is to enhance churn prediction by modeling churn as a dyadic phenomena, provide an enhanced evaluation for the social tie strength based on customers social interactions, and to study the effect of strong social ties on churn propagation over mobile telecom networks.},
booktitle = {Proceedings of the 3rd Workshop on Data-Driven User Behavioral Modeling and Mining from Social Media},
pages = {11–12},
numpages = {2},
keywords = {social network analysis, social tie strength, churn prediction},
location = {Shanghai, China},
series = {DUBMOD '14}
}

@inproceedings{10.1145/3384544.3384551,
author = {Tuck, Wong Keng and Chien-Le, Goh and Hu, Ng},
title = {A False Negative Cost Minimization Ensemble Methods for Customer Churn Analysis},
year = {2020},
isbn = {9781450376655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384544.3384551},
doi = {10.1145/3384544.3384551},
abstract = {The primary objective of this research is to develop hybrid decision tree induction methods based on the decision tree C4.5 algorithm and ensemble methods, taking into account cost-sensitivity for the purpose of minimizing either misclassification cost, false negative cost or false positive cost. This paper proposed two cost-sensitive learning methods by modifying the model weight of AdaBoost.M1 for churn analysis in the telecommunication industry. Method 1 applies the ratio of false negative cost over true negative cost to make the weight of false negative heavier than the weight of false positive. While Method 2 combines error rate weighting with false negative cost weighting in order to let examples have heavier weight values for future training in the next learning cycle. The proposed methods have been evaluated with a series of experiments to prove its ability to reduce either false negative cost or misclassification costs. Microsoft Azure Machine Learning Telco Customer Churn and IBM Watson Studio Telecommunication Customer Churn datasets, which include the cost value for each instance, are used for the experiments. The proposed Method 1 able to obtain the lowest false negative cost comparing with the original AdaBoost.M1.},
booktitle = {Proceedings of the 2020 9th International Conference on Software and Computer Applications},
pages = {276–280},
numpages = {5},
keywords = {ensemble methods, decision tree, cost-sensitive},
location = {Langkawi, Malaysia},
series = {ICSCA 2020}
}

@inproceedings{10.1145/3319921.3319937,
author = {Zhong, Junmei and Li, William},
title = {Predicting Customer Churn in the Telecommunication Industry by Analyzing Phone Call Transcripts with Convolutional Neural Networks},
year = {2019},
isbn = {9781450361286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319921.3319937},
doi = {10.1145/3319921.3319937},
abstract = {For telecommunication service providers, a principle method for reducing costs and generating revenue is to focus on retaining existing customers rather than acquiring new customers. To support this strategy, it is important to understand customer concerns as early as possible to prevent churn: The customer action of canceling a subscription and moving to a new provider. In this paper, we use actual customer phone call data and develop the convolutional neural network (CNN)-based predictive model to detect churn signals from transcript data of phone calls. Experimental results show that when sufficient training data is provided with our text annotation method, our CNN-based predictive model generates state-of-the-art performance in churn prediction.},
booktitle = {Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence},
pages = {55–59},
numpages = {5},
keywords = {Artificial intelligence (AI), convolutional neural networks (CNN), churn prediction, machine learning, text mining, natural language processing (NLP)},
location = {Suzhou, China},
series = {ICIAI 2019}
}

@inproceedings{10.5555/3172795.3172853,
author = {Fan, Xueqi and Iacob, Mihai and Nicolae, Mihai and Dong, Eric},
title = {Machine Learning Basics with IBM Data Science Experience},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {The growing body of digital data has given rise to unprecedented opportunities for and humanity advancement and competitive advantage in the enterprise and beyond. Machine learning enables learning from large datasets to solve problems. Its applicability spans many industries. For instance, in the finance industry, machine learning is used to score clients on transaction risk based on client spending history. In government, agencies use machine learning to assesses likelihood of that individual will need multiple agency support for social services to proactively engage agencies, determine best outcome, and optimize costs. The impact of machine learning is heartfelt on end users of almost every technology service. For instance, the runaway success of Netflix is partly due to its recommendation engine which has machine learning at its core. Machine learning is particularly well-suited to solve industry-specific problems where data is abundant. Loan acceptance prediction, customer churn prediction, fraud detection are examples of such problems. This drives home the point that machine learning influences almost everything we do.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {340},
numpages = {1},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}

@inproceedings{10.1145/3299815.3314454,
author = {Tsaku, Nelson Zange and Kosaraju, Sai},
title = {Boosting Recommendation Systems through an Offline Machine Learning Evaluation Approach},
year = {2019},
isbn = {9781450362511},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299815.3314454},
doi = {10.1145/3299815.3314454},
abstract = {Nowadays, recommendation systems are widely deployed to suggest a variety of products and services for target users. Practical examples of recommendation systems that we daily encounter include social, educational, and political services such as academic courses, movies, travel, music, and news feed on the web. Current recommendation systems can be categorized into threefold: knowledge-based, collaborative filtering, and content-based systems. Knowledge-based recommendation systems are based on domain knowledge without user-specific data. Collaborative filtering provides recommendations based on existing user's historical record, which can be a problem when the user is new to the platform. Content-based recommendations build models based on a number of records on product transactions. In this paper, we introduce the three recommendation systems, then suggest a new strategy that integrates domain knowledge for new users into a machine learning based recommendation system for existing users. We also propose an offline/online evaluation strategy to reduce customer churn, which enables the deployment of accurate recommendations for both new and existing users. Using the movie Tweetings dataset, we implement each recommendation system and generate a boosted system which addresses the issues caused by current recommendation systems.},
booktitle = {Proceedings of the 2019 ACM Southeast Conference},
pages = {182–185},
numpages = {4},
keywords = {Collaborative Filtering, Matrix Factorization, Recommendation System, Content-based Recommendations, Machine Learning},
location = {Kennesaw, GA, USA},
series = {ACM SE '19}
}

@inproceedings{10.1145/3105831.3105832,
author = {Abd-Allah, Marwa N. and El-Beltagy, Samhaa R. and Salah, Akram},
title = {DyadChurn: Customer Churn Prediction Using Strong Social Ties},
year = {2017},
isbn = {9781450352208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3105831.3105832},
doi = {10.1145/3105831.3105832},
abstract = {The increase in mobile phone subscriptions in recent years, has led to near market saturation in the telecom industry. As a result, it has become harder for telecom providers to acquire new customers, and the need for retaining existing ones has become of paramount importance. Because of fierce competition between different telecom providers and because the ease of which customers can move from one provider to another, all telecom service providers suffer from customer churn. In this paper, we propose a dyadic based churn prediction model, DyadChurn, where customer churn is modeled through social influence that propagates in the telecom network over strong social ties. We propose a novel method for evaluating social tie strength between telecom customers. We then, incorporate strong social ties in an influence propagation model to predict the set of future potential churners. The evaluation of the proposed dyadic based churn prediction model has been done using a real dataset, from one of the largest telecom companies in Egypt. The experimental results showed that the "length of calls" between customers is the most effective attribute in predicting social influence that result in churning. The results also showed that strong social ties (as opposed to weak ties) were the most effective ties in determining churn. Using strong social ties only enhanced the prediction accuracy (in terms of the lift curve) by more than 20%, when compared to a diffusion model.},
booktitle = {Proceedings of the 21st International Database Engineering &amp; Applications Symposium},
pages = {253–263},
numpages = {11},
keywords = {Churn prediction, Social tie strength, Social network analysis},
location = {Bristol, United Kingdom},
series = {IDEAS 2017}
}

@inproceedings{10.1145/3352411.3352449,
author = {Zhang, Sheng and Tan, Xueliang and Wang, Jiawen and Chen, Jianghang and Lai, Xinjun},
title = {Modeling Customers' Loyalty Using Ten Years' Automobile Repair and Maintenance Data: Machine Learning Approaches},
year = {2019},
isbn = {9781450371414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352411.3352449},
doi = {10.1145/3352411.3352449},
abstract = {Automotive aftermarket (e.g. repair and maintenance) is one of the most lucrative business in the entire automotive industry chain. However, with the fierce competition recently, many service providers (also known as 4S shops) are facing a problem of customer churn. It would be most valuable to investigate the determinants of customers' loyalty. Ten years' data of a 4S shop is analyzed where customers' social-demographics, maintenance patterns and habits, car characteristics, repair types, fees and discounts, etc. are available, and machine learning approaches are employed. This paper investigates the causes for the customer churn in 4S shops, and proposes several solutions to improve the management and operation of 4S shops. Results from this analysis shed light on customers' loyalty behaviors and automotive industry customer relationship management.},
booktitle = {Proceedings of the 2019 2nd International Conference on Data Science and Information Technology},
pages = {242–248},
numpages = {7},
keywords = {Data mining, Automobile 4S shop, Customer churn, Behavioral prediction, Customer relationship management},
location = {Seoul, Republic of Korea},
series = {DSIT 2019}
}

@article{10.1145/3308897.3308962,
author = {Wassermann, Sarah and Wehner, Nikolas and Casas, Pedro},
title = {Machine Learning Models for YouTube QoE and User Engagement Prediction in Smartphones},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0163-5999},
url = {https://doi.org/10.1145/3308897.3308962},
doi = {10.1145/3308897.3308962},
abstract = {Measuring and monitoring YouTube Quality of Experience is a challenging task, especially when dealing with cellular networks and smartphone users. Using a large-scale database of crowdsourced YouTube-QoE measurements in smartphones, we conceive multiple machine-learning models to infer different YouTube-QoE-relevant metrics and userbehavior- related metrics from network-level measurements, without requiring root access to the smartphone, video-player embedding, or any other reverse-engineering-like approaches. The dataset includes measurements from more than 360 users worldwide, spanning over the last five years. Our preliminary results suggest that QoE-based monitoring of YouTube mobile can be realized through machine learning models with high accuracy, relying only on network-related features and without accessing any higher-layer metric to perform the estimations.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = jan,
pages = {155–158},
numpages = {4},
keywords = {qoe, machine learning, smartphone measurements}
}

@article{10.1145/3343440,
author = {Kaur, Harsurinder and Pannu, Husanbir Singh and Malhi, Avleen Kaur},
title = {A Systematic Review on Imbalanced Data Challenges in Machine Learning: Applications and Solutions},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3343440},
doi = {10.1145/3343440},
abstract = {In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {79},
numpages = {36},
keywords = {machine learning, data analysis, sampling, Data imbalance}
}

@article{10.14778/2824032.2824087,
author = {Kumar, Arun and Jalal, Mona and Yan, Boqun and Naughton, Jeffrey and Patel, Jignesh M.},
title = {Demonstration of Santoku: Optimizing Machine Learning over Normalized Data},
year = {2015},
issue_date = {August 2015},
publisher = {VLDB Endowment},
volume = {8},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2824032.2824087},
doi = {10.14778/2824032.2824087},
abstract = {Advanced analytics is a booming area in the data management industry and a hot research topic. Almost all toolkits that implement machine learning (ML) algorithms assume that the input is a single table, but most relational datasets are not stored as single tables due to normalization. Thus, analysts often join tables to obtain a denormalized table. Also, analysts typically ignore any functional dependencies among features because ML toolkits do not support them. In both cases, time is wasted in learning over data with redundancy. We demonstrate Santoku, a toolkit to help analysts improve the performance of ML over normalized data. Santoku applies the idea of factorized learning and automatically decides whether to denormalize or push ML computations through joins. Santoku also exploits database dependencies to provide automatic insights that could help analysts with exploratory feature selection. It is usable as a library in R, which is a popular environment for advanced analytics. We demonstrate the benefits of Santoku in improving ML performance and helping analysts with feature selection.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {1864–1867},
numpages = {4}
}

@inproceedings{10.1145/3307334.3326070,
author = {Xiao, Ao and Liu, Yunhao and Li, Yang and Qian, Feng and Li, Zhenhua and Bai, Sen and Liu, Yao and Xu, Tianyin and Xin, Xianlong},
title = {An In-Depth Study of Commercial MVNO: Measurement and Optimization},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326070},
doi = {10.1145/3307334.3326070},
abstract = {Recent years have witnessed the rapid growth of mobile virtual network operators (MVNOs), which operate on top of the existing cellular infrastructures of base carriers while offering cheaper or more flexible data plans compared to those of the base carriers. In this paper, we present a nearly two-year measurement study towards understanding various key aspects of today's MVNO ecosystem, including its architecture, performance, economics, customers, and the complex interplay with the base carrier. Our study focuses on a large commercial MVNO with reviseabout 1 million customers, operating atop a nation-wide base carrier. Our measurements clarify several key concerns raised by MVNO customers, such as inaccurate billing and potential performance discrimination with the base carrier. We also leverage big data analytics and machine learning to optimize an MVNO's key businesses such as data plan reselling and customer churn mitigation. Our proposed techniques can help achieve %will lead to higher revenues and improved services for commercial MVNOs.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {457–468},
numpages = {12},
keywords = {churn mitigation, network performance, data prediction, machine learning, mvno},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@article{10.5555/2946645.2946649,
author = {Blaser, Rico and Fryzlewicz, Piotr},
title = {Random Rotation Ensembles},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
abstract = {In machine learning, ensemble methods combine the predictions of multiple base learners to construct more accurate aggregate predictions. Established supervised learning algorithms inject randomness into the construction of the individual base learners in an effort to promote diversity within the resulting ensembles. An undesirable side effect of this approach is that it generally also reduces the accuracy of the base learners. In this paper, we introduce a method that is simple to implement yet general and effective in improving ensemble diversity with only modest impact on the accuracy of the individual base learners. By randomly rotating the feature space prior to inducing the base learners, we achieve favorable aggregate predictions on standard data sets compared to state of the art ensemble methods, most notably for tree-based ensembles, which are particularly sensitive to rotation.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {126–151},
numpages = {26},
keywords = {feature rotation, ensemble diversity, smooth decision boundary}
}

@inproceedings{10.1145/3224207.3224217,
author = {Zhu, Bing and Xie, Guicai and Yuan, Yuan and Duan, Yiqin},
title = {Investigating Decision Tree in Churn Prediction with Class Imbalance},
year = {2018},
isbn = {9781450364188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3224207.3224217},
doi = {10.1145/3224207.3224217},
abstract = {Class imbalance presents significant challenges to customer churn prediction. Traditional machine learning algorithms like decision tree tend to be biased towards majority class. In this paper, we comprehensively study the performance of decision tree in churn prediction with class imbalance. We investigate the issue of pruning setting and optimal sampling strategy based on a recently developed expected maximum profit criterion. The experiments present some different conclusions from the previous research when the area under the ROC curve is used and the optimal sampling strategy are recommended. Our findings provides a useful guideline for usage of decision tree in churn prediction.},
booktitle = {Proceedings of the International Conference on Data Processing and Applications},
pages = {11–15},
numpages = {5},
keywords = {expected maximum profit measure, Churn prediction, decision tree, class imbalance},
location = {Guangdong, China},
series = {ICDPA 2018}
}

@inproceedings{10.1145/3231884.3231900,
author = {Zhu, Bing and Pan, Yin and Gao, Zihan},
title = {Application of Active Learning for Churn Prediction with Class Imbalance},
year = {2018},
isbn = {9781450364324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3231884.3231900},
doi = {10.1145/3231884.3231900},
abstract = {Churn prediction is a major focus that all the companies need to concern. Many studies have shown that class imbalance has a significant impact on churn prediction, but there is still no consensus on which technique is the best to cope with this issue. Recently, active learning has proved to be effective for imbalance learning. We try to apply it to churn prediction in this paper. In order to verify its effectiveness, we carry out experiments on six real-world data sets from the telecommunication industry and compare its performance with the other three benchmark resampling methods. Besides using the AUC to measure the accuracy of classification, we take the profit-based measure --- expected maximum profit (EMP) into account which measures the real cost and benefit produced by the models. The experimental results show that active learning is a good choice in dealing with the class imbalance problem in churn prediction.},
booktitle = {Proceedings of the 2018 International Conference on Machine Learning Technologies},
pages = {89–93},
numpages = {5},
keywords = {Class Imbalance, Churn Prediction, Active Learning, Profit-based Measure},
location = {Jinan, China},
series = {ICMLT '18}
}

@inproceedings{10.1145/3195106.3195178,
author = {Cui, Shaoying and Ding, Ning},
title = {Construction of a Bank Customer Data Warehouse and an Application of Data Mining},
year = {2018},
isbn = {9781450363532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195106.3195178},
doi = {10.1145/3195106.3195178},
abstract = {In this era of strong competition, data mining can provide effective support to bank operators in their effort to analyze and forecast the real needs of their customers. Applying bank data mining results to the actual business enables banks to develop products that not only meet customer needs but also deliver maximum bank profitability. In this paper, a data mining model for bank customers is established, and after extraction and transformation, the data are loaded into a data warehouse specifically built for that purpose. Using the data mining platform, we conduct multidimensional analysis of the customer information to uncover characteristics of their preferences. The goal of this research is to help facilitate new ideas and methods for the analysis and prediction of bank customer data.},
booktitle = {Proceedings of the 2018 10th International Conference on Machine Learning and Computing},
pages = {161–166},
numpages = {6},
keywords = {data mining, Bank customer information, multidimensional data analysis, data warehouse},
location = {Macau, China},
series = {ICMLC 2018}
}

@inproceedings{10.1145/3369114.3369135,
author = {Awang, Mohd Khalid and Makhtar, Mokhairi and Mohamed, Mohamad Afendee},
title = {An Ensemble Method with Cost Function on Churn Prediction},
year = {2019},
isbn = {9781450372534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369114.3369135},
doi = {10.1145/3369114.3369135},
abstract = {Accurate customer churn classification is vital in any business organisation due to the higher cost involved in getting new customers. In telecommunication businesses, companies have used various types of single classifiers to classify customer churn, but the classification accuracy is still relatively low. However, the classification accuracy can be improved by integrating decisions from multiple classifiers through an ensemble method. Despite having the ability to produce higher classification accuracy, the ensemble method tends to produce similar or redundant classifiers. Therefore, this paper aims to achieve higher classification accuracy and at the same time, minimising ensemble classifiers by constructing a new ensemble method based on dimensionality reduction in soft set theory. The combination of ensemble classifier is calculated based on the simple majority voting algorithm. The performance measure used in determining the optimal subset of classifiers is the combination of Accuracy (ACC), True Negative Rate (TNR) and True Positive Rate (TPR). The proposed soft set ensemble methods (SSPN and SSSC) are systematically evaluated using customer churn data set taken from one of the local Telco companies in Malaysia. The selection and combination algorithm (SSSC) has proven its supremacy by producing accuracy (ACC) of 87.0% for local Telco data set and 94.0% for UCI data set, which is better than any other single classifier. This work proved that the proposed soft ensemble method could search for the minimum number of classifiers in the ensemble repository while at the same time improving the classification performance. In conclusion, the proposed soft ensemble method not only reduces the number of members of the ensemble but is also able to produce the highest classification accuracy.},
booktitle = {Proceedings of the 2019 3rd International Conference on Advances in Artificial Intelligence},
pages = {117–121},
numpages = {5},
keywords = {Ensemble Method, Ensemble Pruning, Churn Prediction},
location = {Istanbul, Turkey},
series = {ICAAI 2019}
}

@inproceedings{10.1145/3009977.3010073,
author = {I, Shahid K and Chaudhury, Santanu},
title = {Scalable Clustering and Applications},
year = {2016},
isbn = {9781450347532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3009977.3010073},
doi = {10.1145/3009977.3010073},
abstract = {Large scale machine learning is becoming an active research area recently. Most of the existing clustering algorithms cannot handle big data due to its high time and space complexity. Among the clustering algorithms, eigen vector based clustering, such as Spectral clustering, shows very good accuracy, but it has cubic time complexity. There are various methods proposed to reduce the time and space complexity for eigen decomposition such as Nystr\"{o}m method, Lanc-zos method etc. Nystr\"{o}m method has linear time complexity in terms of number of data points, but has cubic time complexity in terms of number of sampling points. To reduce this, various Rank k approximation methods also proposed, but which are less efficient compare to the normalized spectral clustering. In this paper we propose a two step algorithm for spectral clustering to reduce the time complexity toO(nmk + m2k'), by combining both Nystr\"{o}m and Lanczos method, where k is the number of clusters and k' is the rank k approximation of the sampling matrix (k &lt; k' &lt;&lt; m &lt;&lt; n). It shows very good results, with various data sets, image segmentation problems and churn prediction of a telecommunication data set, even with very low sampling (for 10 Million \texttimes{} 10 Million matrix, sampled only 100 columns) with lesser time, which confirms the validity of the algorithm.},
booktitle = {Proceedings of the Tenth Indian Conference on Computer Vision, Graphics and Image Processing},
articleno = {34},
numpages = {7},
keywords = {segmentation and grouping, large scale machine learning},
location = {Guwahati, Assam, India},
series = {ICVGIP '16}
}

@inproceedings{10.1145/3352411.3352421,
author = {Zheng, NaiSong and Jiang, XiaoWei and Ao, Yibo and Zhao, Xi},
title = {Prediction of Tariff Package Model Using ROF-LGB Algorithm},
year = {2019},
isbn = {9781450371414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352411.3352421},
doi = {10.1145/3352411.3352421},
abstract = {With the slowing growth of the telecommunication market and the intense competition for existing customers, Customer Churn Management has become a crucial task for all mobile network operators. Recommendation models based on customer behaviors are widely used by operators to provide diverse telecom tariff packages for suitable people and thus improve customer satisfaction. To address the low precision rate and data granularity of prior studies, this study combined rotation forest (ROF) and LightGBM and construct a hybrid algorithm (ROF-LGB). Grid search method was used in parameter tuning, and ten-fold cross-validation method was used to prevent overfitting. Using mobile data generated by operators, ROF-LGB method was tested and compared with other five traditional machine learning methods. The results showed that ROF-LGB method achieved better performance with better precision rate and execution efficiency in telecom tariff package recommendation.},
booktitle = {Proceedings of the 2019 2nd International Conference on Data Science and Information Technology},
pages = {54–58},
numpages = {5},
keywords = {ROF-LGB, LightGBM, Prediction, Tariff Package},
location = {Seoul, Republic of Korea},
series = {DSIT 2019}
}

@inproceedings{10.1145/2908446.2908488,
author = {Galal, Mohamed and Hassan, Ghada and Aref, Mostafa},
title = {Developing a Personalized Multi-Dimensional Framework Using Business Intelligence Techniques in Banking},
year = {2016},
isbn = {9781450340625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2908446.2908488},
doi = {10.1145/2908446.2908488},
abstract = {Intelligent techniques have been used in the marketing and sales sectors of business to improve analysis, increase revenues and save time. In customer-centric institutions, one of the areas in which intelligent techniques and data mining algorithms have been used is the personalization for enhanced CRM (Customer Relationship Management) performance. However, with a growing number of customers, the diversity of products on offer, the complex behavior of customer groups and the continuous change of personalization parameters, producing a tailored personalized recommendation that predicts their future needs is a challenging task.In this paper, we propose multi dimension personalization framework architecture to improve personalized targeting. The framework presented improves on the automation of existing systems by using multiple supervised and unsupervised data mining techniques, and enhances the level of targeting by considering more effective dimensions in multiple stages of the framework. A theoretical case study explaining the practical working and perceived advantages of the new framework is presented.},
booktitle = {Proceedings of the 10th International Conference on Informatics and Systems},
pages = {21–27},
numpages = {7},
keywords = {CRM, Object Profiling, Recommendation, Intelligent DSS, Business Intelligence, Customer churn, Clustering, Association Rules, Group Profile, Personalization, Dimensional Modeling, User Profile},
location = {Giza, Egypt},
series = {INFOS '16}
}

@inproceedings{10.1145/2882903.2882952,
author = {Kumar, Arun and Naughton, Jeffrey and Patel, Jignesh M. and Zhu, Xiaojin},
title = {To Join or Not to Join? Thinking Twice about Joins before Feature Selection},
year = {2016},
isbn = {9781450335317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2882903.2882952},
doi = {10.1145/2882903.2882952},
abstract = {Closer integration of machine learning (ML) with data processing is a booming area in both the data management industry and academia. Almost all ML toolkits assume that the input is a single table, but many datasets are not stored as single tables due to normalization. Thus, analysts often perform key-foreign key joins to obtain features from all base tables and apply a feature selection method, either explicitly or implicitly, with the aim of improving accuracy. In this work, we show that the features brought in by such joins can often be ignored without affecting ML accuracy significantly, i.e., we can "avoid joins safely." We identify the core technical issue that could cause accuracy to decrease in some cases and analyze this issue theoretically. Using simulations, we validate our analysis and measure the effects of various properties of normalized data on accuracy. We apply our analysis to design easy-to-understand decision rules to predict when it is safe to avoid joins in order to help analysts exploit this runtime-accuracy trade-off. Experiments with multiple real normalized datasets show that our rules are able to accurately predict when joins can be avoided safely, and in some cases, this led to significant reductions in the runtime of some popular feature selection methods.},
booktitle = {Proceedings of the 2016 International Conference on Management of Data},
pages = {19–34},
numpages = {16},
keywords = {machine learning, feature selection, VC dimension, key-foreign key joins, feature engineering, functional dependencies, advanced analytics},
location = {San Francisco, California, USA},
series = {SIGMOD '16}
}

@inproceedings{10.1145/2914586.2914610,
author = {Almuqren, Latifah and Cristea, Alexandra I.},
title = {Framework for Sentiment Analysis of Arabic Text},
year = {2016},
isbn = {9781450342476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2914586.2914610},
doi = {10.1145/2914586.2914610},
abstract = {This paper analyses challenges, and provides a model and a framework for mining Arabic tweets to measure customer satisfaction toward telecom companies in Saudi Arabia, to predict the ratio of customer churn and overcome the specific challenges with the semantic sentiment analysis of Arabic text.},
booktitle = {Proceedings of the 27th ACM Conference on Hypertext and Social Media},
pages = {315–317},
numpages = {3},
keywords = {sentiment, arabic, twitter, semantic sentiment analysis (SSA)},
location = {Halifax, Nova Scotia, Canada},
series = {HT '16}
}

@inproceedings{10.5555/3192424.3192638,
author = {\'{O}skarsd\'{o}ttir, Mar\'{\i}a and Bravo, Cristi\'{a}n and Verbeke, Wouter and Sarraute, Carlos and Baesens, Bart and Vanthienen, Jan},
title = {A Comparative Study of Social Network Classifiers for Predicting Churn in the Telecommunication Industry},
year = {2016},
isbn = {9781509028467},
publisher = {IEEE Press},
abstract = {Relational learning in networked data has been shown to be effective in a number of studies. Relational learners, composed of relational classifiers and collective inference methods, enable the inference of nodes in a network given the existence and strength of links to other nodes. These methods have been adapted to predict customer churn in telecommunication companies showing that incorporating them may give more accurate predictions. In this research, the performance of a variety of relational learners is compared by applying them to a number of CDR datasets originating from the telecommunication industry, with the goal to rank them as a whole and investigate the effects of relational classifiers and collective inference methods separately. Our results show that collective inference methods do not improve the performance of relational classifiers and the best performing relational classifier is the network-only link-based classifier, which builds a logistic model using link-based measures for the nodes in the network.},
booktitle = {Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {1151–1158},
numpages = {8},
location = {Davis, California},
series = {ASONAM '16}
}

@inproceedings{10.1145/2723372.2723713,
author = {Kumar, Arun and Naughton, Jeffrey and Patel, Jignesh M.},
title = {Learning Generalized Linear Models Over Normalized Data},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723372.2723713},
doi = {10.1145/2723372.2723713},
abstract = {Enterprise data analytics is a booming area in the data management industry. Many companies are racing to develop toolkits that closely integrate statistical and machine learning techniques with data management systems. Almost all such toolkits assume that the input to a learning algorithm is a single table. However, most relational datasets are not stored as single tables due to normalization. Thus, analysts often perform key-foreign key joins before learning on the join output. This strategy of learning after joins introduces redundancy avoided by normalization, which could lead to poorer end-to-end performance and maintenance overheads due to data duplication. In this work, we take a step towards enabling and optimizing learning over joins for a common class of machine learning techniques called generalized linear models that are solved using gradient descent algorithms in an RDBMS setting. We present alternative approaches to learn over a join that are easy to implement over existing RDBMSs. We introduce a new approach named factorized learning that pushes ML computations through joins and avoids redundancy in both I/O and computations. We study the tradeoff space for all our approaches both analytically and empirically. Our results show that factorized learning is often substantially faster than the alternatives, but is not always the fastest, necessitating a cost-based approach. We also discuss extensions of all our approaches to multi-table joins as well as to Hive.},
booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
pages = {1969–1984},
numpages = {16},
keywords = {joins, machine learning, analytics, feature engineering},
location = {Melbourne, Victoria, Australia},
series = {SIGMOD '15}
}

@inproceedings{10.1145/2808797.2808850,
author = {Backiel, Aim\'{e}e and Verbinnen, Yannick and Baesens, Bart and Claeskens, Gerda},
title = {Combining Local and Social Network Classifiers to Improve Churn Prediction},
year = {2015},
isbn = {9781450338547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808797.2808850},
doi = {10.1145/2808797.2808850},
abstract = {Past research has shown that both social and local features are informative for customer churn, however some studies have found that combining both kinds of data into a single model is ineffective. People who churn based on their neighbors' behavior are a distinct subset of customers from those who churn for personal reasons. However, for an effective retention campaign, it is desired to identify both groups of likely churners, attempt to explain the factors that lead to churn in both cases, and still determine the customers most likely to churn so they can be contacted. The goal of this research is to evaluate different techniques for combining features and models based on customer attributes and customer social networks to identify the best approaches to deal with this problem.},
booktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015},
pages = {651–658},
numpages = {8},
location = {Paris, France},
series = {ASONAM '15}
}

@inproceedings{10.1145/2808797.2808821,
author = {G\"{o}k, Mehmet and \"{O}zyer, Tansel and Jida, Jamal},
title = {A Case Study for the Churn Prediction in Turksat Internet Service Subscription},
year = {2015},
isbn = {9781450338547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808797.2808821},
doi = {10.1145/2808797.2808821},
abstract = {Churn prediction is a customer relationship process that predicts for customers who are at the brink of transferring all the business to competitor. It is predicted by modeling customer behaviors in order to extract patterns. An acquaintance of a customer is more costly than retainment of an existing customer. Churn predictions shed light on members about to leave the service and support promotion activities. These attempts are utilized to avoid subscription cancellation of existing customers. Nowadays, telecommunication companies take churn prediction very serious. They strive for monitoring customers in the business by using various applications in systematic approach. Our study is based on leading internet service providing company, Turksat Satellite Communications and Cable TV Operations Company's customer behavior analysis. It is the leading internet service provider of Turkey operating in telecommunications sector. We have created a two-phase solution utilizing data mining techniques. These are time series clustering and classification techniques.},
booktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015},
pages = {1220–1224},
numpages = {5},
keywords = {churn prediction, Customer relationship management, recursive partitioning, time series clustering, hierarchical clustering, k-means clustering, support vector machines, data mining, classification},
location = {Paris, France},
series = {ASONAM '15}
}

@inproceedings{10.5555/2449360.2449382,
author = {Sato, Takeshi and Huang, Bingquan and Lefait, Guillem and Kechadi, M-T. and Buckley, B.},
title = {Kernel-Based Principal Components Analysis on Large Telecommunication Data},
year = {2009},
isbn = {9781920682828},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Linear Principal Components Analysis (LPCA) is known for its simplicity to reduce the features dimensionality. An extension of LPCA, Kernel Principal Components Analysis (KPCA), outperforms LPCA when applied on non-linear data in high dimensional feature space. However, on large datasets with high input space, KPCA deals with a memory issue and imbalance classification problems with difficulty. This paper presents an approach to reduce the complexity of the training process of KPCA by condensing the training set with sampling and clustering techniques as pre-processing step. The experiments were carried out on a large real-world Telecommunication dataset and were assessed on a churn prediction task. The experiments show that the proposed approach, when combined with clustering techniques, can efficiently reduce feature dimension and outperforms standard PCA for customer churn prediction.},
booktitle = {Proceedings of the Eighth Australasian Data Mining Conference - Volume 101},
pages = {109–115},
numpages = {7},
keywords = {kernel PCA, imbalanced classification, churn prediction, clustering},
location = {Melbourne, Australia},
series = {AusDM '09}
}

@article{10.14778/3236187.3269462,
author = {Hasani, Sona and Thirumuruganathan, Saravanan and Asudeh, Abolfazl and Koudas, Nick and Das, Gautam},
title = {Efficient Construction of Approximate Ad-Hoc ML Models through Materialization and Reuse},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3236187.3269462},
doi = {10.14778/3236187.3269462},
abstract = {Machine learning has become an essential toolkit for complex analytic processing. Data is typically stored in large data warehouses with multiple dimension hierarchies. Often, data used for building an ML model are aligned on OLAP hierarchies such as location or time. In this paper, we investigate the feasibility of efficiently constructing approximate ML models for new queries from previously constructed ML models by leveraging the concepts of model materialization and reuse. For example, is it possible to construct an approximate ML model for data from the year 2017 if one already has ML models for each of its quarters? We propose algorithms that can support a wide variety of ML models such as generalized linear models for classification along with K-Means and Gaussian Mixture models for clustering. We propose a cost based optimization framework that identifies appropriate ML models to combine at query time and conduct extensive experiments on real-world and synthetic datasets. Our results indicate that our framework can support analytic queries on ML models, with superior performance, achieving dramatic speedups of several orders in magnitude on very large datasets.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {1468–1481},
numpages = {14}
}

@article{10.14778/3236187.3236199,
author = {Hasani, Sona and Thirumuruganathan, Saravanan and Asudeh, Abolfazl and Koudas, Nick and Das, Gautam},
title = {Efficient Construction of Approximate Ad-Hoc ML Models through Materialization and Reuse},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3236187.3236199},
doi = {10.14778/3236187.3236199},
abstract = {Machine learning has become an essential toolkit for complex analytic processing. Data is typically stored in large data warehouses with multiple dimension hierarchies. Often, data used for building an ML model are aligned on OLAP hierarchies such as location or time. In this paper, we investigate the feasibility of efficiently constructing approximate ML models for new queries from previously constructed ML models by leveraging the concepts of model materialization and reuse. For example, is it possible to construct an approximate ML model for data from the year 2017 if one already has ML models for each of its quarters? We propose algorithms that can support a wide variety of ML models such as generalized linear models for classification along with K-Means and Gaussian Mixture models for clustering. We propose a cost based optimization framework that identifies appropriate ML models to combine at query time and conduct extensive experiments on real-world and synthetic datasets. Our results indicate that our framework can support analytic queries on ML models, with superior performance, achieving dramatic speedups of several orders in magnitude on very large datasets.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {1468–1481},
numpages = {14}
}

@article{10.5555/3236187.3269462,
author = {Hasani, Sona and Thirumuruganathan, Saravanan and Asudeh, Abolfazl and Koudas, Nick and Das, Gautam},
title = {Efficient Construction of Approximate Ad-Hoc ML Models through Materialization and Reuse},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
abstract = {Machine learning has become an essential toolkit for complex analytic processing. Data is typically stored in large data warehouses with multiple dimension hierarchies. Often, data used for building an ML model are aligned on OLAP hierarchies such as location or time. In this paper, we investigate the feasibility of efficiently constructing approximate ML models for new queries from previously constructed ML models by leveraging the concepts of model materialization and reuse. For example, is it possible to construct an approximate ML model for data from the year 2017 if one already has ML models for each of its quarters? We propose algorithms that can support a wide variety of ML models such as generalized linear models for classification along with K-Means and Gaussian Mixture models for clustering. We propose a cost based optimization framework that identifies appropriate ML models to combine at query time and conduct extensive experiments on real-world and synthetic datasets. Our results indicate that our framework can support analytic queries on ML models, with superior performance, achieving dramatic speedups of several orders in magnitude on very large datasets.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {1468–1481},
numpages = {14}
}

@article{10.14778/3157794.3157804,
author = {Shah, Vraj and Kumar, Arun and Zhu, Xiaojin},
title = {Are Key-Foreign Key Joins Safe to Avoid When Learning High-Capacity Classifiers?},
year = {2017},
issue_date = {November 2017},
publisher = {VLDB Endowment},
volume = {11},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3157794.3157804},
doi = {10.14778/3157794.3157804},
abstract = {Machine learning (ML) over relational data is a booming area of data management. While there is a lot of work on scalable and fast ML systems, little work has addressed the pains of sourcing data for ML tasks. Real-world relational databases typically have many tables (often, dozens) and data scientists often struggle to even obtain all tables for joins before ML. In this context, Kumar et al. showed recently that key-foreign key dependencies (KFKDs) between tables often lets us avoid such joins without significantly affecting prediction accuracy-an idea they called "avoiding joins safely." While initially controversial, this idea has since been used by multiple companies to reduce the burden of data sourcing for ML. But their work applied only to linear classifiers. In this work, we verify if their results hold for three popular high-capacity classifiers: decision trees, non-linear SVMs, and ANNs. We conduct an extensive experimental study using both real-world datasets and simulations to analyze the effects of avoiding KFK joins on such models. Our results show that these high-capacity classifiers are surprisingly and counter-intuitively more robust to avoiding KFK joins compared to linear classifiers, refuting an intuition from the prior work's analysis. We explain this behavior intuitively and identify open questions at the intersection of data management and ML theoretical research. All of our code and datasets are available for download from http://cseweb.ucsd.edu/~arunkk/hamlet.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {366–379},
numpages = {14}
}

@article{10.1145/3349265,
author = {Barua, Hrishav Bakul and Mondal, Kartick Chandra},
title = {A Comprehensive Survey on Cloud Data Mining (CDM) Frameworks and Algorithms},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3349265},
doi = {10.1145/3349265},
abstract = {Data mining is used for finding meaningful information out of a vast expanse of data. With the advent of Big Data concept, data mining has come to much more prominence. Discovering knowledge out of a gigantic volume of data efficiently is a major concern as the resources are limited. Cloud computing plays a major role in such a situation. Cloud data mining fuses the applicability of classical data mining with the promises of cloud computing. This allows it to perform knowledge discovery out of huge volumes of data with efficiency. This article presents the existing frameworks, services, platforms, and algorithms for cloud data mining. The frameworks and platforms are compared among each other based on similarity, data mining task support, parallelism, distribution, streaming data processing support, fault tolerance, security, memory types, storage systems, and others. Similarly, the algorithms are grouped on the basis of parallelism type, scalability, streaming data mining support, and types of data managed. We have also provided taxonomies on the basis of data mining techniques such as clustering, classification, and association rule mining. We also have attempted to discuss and identify the major applications of cloud data mining. The various taxonomies for cloud data mining frameworks, platforms, and algorithms have been identified. This article aims at gaining better insight into the present research realm and directing the future research toward efficient cloud data mining in future cloud systems.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {104},
numpages = {62},
keywords = {big data, velocity, clustering, distributed computing, cloud computing, taxonomy, big data analytics, data mining, volume, machine learning, framework, cloud data mining (CDM), survey, Review, variety, parallelism, data science, classification and association rule mining, graph mining}
}

@inproceedings{10.1145/3349611.3355549,
author = {Wassermann, Sarah and Seufert, Michael and Casas, Pedro and Gang, Li and Li, Kuang},
title = {I See What You See: Real Time Prediction of Video Quality from Encrypted Streaming Traffic},
year = {2019},
isbn = {9781450369275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349611.3355549},
doi = {10.1145/3349611.3355549},
abstract = {We address the problem of real-time QoE monitoring of HAS, from the ISP perspective, focusing in particular on video-resolution analysis. Given the wide adoption of end-to-end encryption, we resort to machine-learning models to predict different video resolution levels in a fine-grained scale, ranging from 144p to 1080p resolution, using as input only packet-level data. The proposed measurement system performs predictions in real time, during the course of an ongoing video-streaming session, with a time granularity as small as one second. We consider the particular case of YouTube video streaming. Empirical evaluations on a large and heterogeneous corpus of YouTube measurements demonstrate that the proposed system can predict video resolution with very high accuracy, and in real time. Different from state of the art, the prediction task is not bound to coarse-grained video quality classes and does not require chunk-detection approaches for feature extraction.},
booktitle = {Proceedings of the 4th Internet-QoE Workshop on QoE-Based Analysis and Management of Data Communication Networks},
pages = {1–6},
numpages = {6},
keywords = {network monitoring, encrypted traffic, qoe, http adaptive video streaming},
location = {Los Cabos, Mexico},
series = {Internet-QoE'19}
}

@article{10.14778/3402755.3402806,
author = {Chaudhuri, Surajit and Narasayya, Vivek},
title = {New Frontiers in Business Intelligence},
year = {2011},
issue_date = {August 2011},
publisher = {VLDB Endowment},
volume = {4},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3402755.3402806},
doi = {10.14778/3402755.3402806},
abstract = {Business intelligence (BI) software is a collection of decision support technologies for the enterprise aimed at enabling knowledge workers such as executives, managers and analysts to make better and faster decisions. The past two decades have seen explosive growth, both in the number of products and services offered and in the adoption of these technologies by industry. This growth has been fueled by the declining cost of acquiring and storing very large amounts of data arising from sources such as customer transactions in banking, retail as well as in E-businesses, RFID tags for inventory tracking, email, query logs for websites, blogs and product reviews. Enterprises today collect data at a finer granularity which is therefore of much larger volume. Businesses are leveraging their data assets aggressively by deploying and experimenting with more sophisticated data analysis techniques to drive business decisions and deliver new functionality such as personalized offers and services to customers. Today, it is difficult to find a successful enterprise that has not leveraged BI technology for their business. For example, BI technology is used in manufacturing for order shipment and customer support, in retail for user profiling to target grocery coupons during checkout, in financial services for claims analysis and fraud detection, in transportation for fleet management, in telecommunications for identifying reasons for customer churn, in utilities for power usage analysis, and in E-business for identifying customers who are likely to respond to a product catalog mailing campaign.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {1502–1503},
numpages = {2}
}

@article{10.1145/3176648,
author = {Skorin-Kapov, Lea and Varela, Mart\'{\i}n and Ho\ss{}feld, Tobias and Chen, Kuan-Ta},
title = {A Survey of Emerging Concepts and Challenges for QoE Management of Multimedia Services},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3176648},
doi = {10.1145/3176648},
abstract = {Quality of Experience (QoE) has received much attention over the past years and has become a prominent issue for delivering services and applications. A significant amount of research has been devoted to understanding, measuring, and modelling QoE for a variety of media services. The next logical step is to actively exploit that accumulated knowledge to improve and manage the quality of multimedia services, while at the same time ensuring efficient and cost-effective network operations. Moreover, with many different players involved in the end-to-end service delivery chain, identifying the root causes of QoE impairments and finding effective solutions for meeting the end users’ requirements and expectations in terms of service quality is a challenging and complex problem. In this article, we survey state-of-the-art findings and present emerging concepts and challenges related to managing QoE for networked multimedia services. Going beyond a number of previously published survey articles addressing the topic of QoE management, we address QoE management in the context of ongoing developments, such as the move to softwarized networks, the exploitation of big data analytics and machine learning, and the steady rise of new and immersive services (e.g., augmented and virtual reality). We address the implications of such paradigm shifts in terms of new approaches in QoE modeling and the need for novel QoE monitoring and management infrastructures.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = may,
articleno = {29},
numpages = {29},
keywords = {crowdsourcing, QoE modeling, encrypted traffic, QoE monitoring, SDN, QoE management, NFV, monitoring probes, data analytics}
}

@article{10.1145/2594473.2594475,
author = {Freitas, Alex A.},
title = {Comprehensible Classification Models: A Position Paper},
year = {2014},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/2594473.2594475},
doi = {10.1145/2594473.2594475},
abstract = {The vast majority of the literature evaluates the performance of classification models using only the criterion of predictive accuracy. This paper reviews the case for considering also the comprehensibility (interpretability) of classification models, and discusses the interpretability of five types of classification models, namely decision trees, classification rules, decision tables, nearest neighbors and Bayesian network classifiers. We discuss both interpretability issues which are specific to each of those model types and more generic interpretability issues, namely the drawbacks of using model size as the only criterion to evaluate the comprehensibility of a model, and the use of monotonicity constraints to improve the comprehensibility and acceptance of classification models by users.},
journal = {SIGKDD Explor. Newsl.},
month = mar,
pages = {1–10},
numpages = {10},
keywords = {Bayesian network classifiers, monotonicity constraint, nearest neighbors, decision table, decision tree, rule induction}
}

@article{10.1145/3022472,
author = {Chen, Chien-Cheng and Hsu, Kuo-Wei and Peng, Wen-Chih},
title = {Exploring Communication Behaviors of Users to Target Potential Users in Mobile Social Networks},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3022472},
doi = {10.1145/3022472},
abstract = {In mobile communication services, users can communicate with each other over different telecommunication carriers. For telecom operators, how to acquire and retain users is a significant and practical task. Note that telecom operators only have their own customer profiles. For the users from other telecom operators, their information is sparse. Thus, given a set of communication logs, the main theme of our work is to identify the potential users who will possibly join the target services in the near future. Since only a limited amount of information is available, one challenging issue is how to extract features from the communication logs. In this article, we propose a Communication-Based Feature Generation (CBFG) framework that extracts features and builds models to infer the potential users. Explicitly, we construct a heterogeneous information network from the communication logs of users. Then, we extract the explicit features, which refer to those calling features of users, from the potential users’ interaction behaviors in the heterogeneous information network. Moreover, from the calling behaviors of users, one could extract the possible community structures of users. Based on the community structures, we further extract the implicit features of users. In light of both explicit and implicit features, we propose an information-gain-based method to select the effective features. According to the features selected, we utilize three popular classifiers (i.e., AdaBoost, Random Forest, and SVM) to build models to target the potential users. In addition, we have designed a sampling approach to extract training data for classifiers. To evaluate our methods, we have conducted experiments on a real dataset. The results of our experiments show that the features extracted by our proposed method can be effective for targeting the potential users.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = aug,
articleno = {79},
numpages = {22},
keywords = {Communication behaviors, feature engineering, mobile social network}
}

@inproceedings{10.1145/3097983.3098123,
author = {Chamberlain, Benjamin Paul and Cardoso, \^{A}ngelo and Liu, C.H. Bryan and Pagliari, Roberto and Deisenroth, Marc Peter},
title = {Customer Lifetime Value Prediction Using Embeddings},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098123},
doi = {10.1145/3097983.3098123},
abstract = {We describe the Customer LifeTime Value (CLTV) prediction system deployed at ASOS.com, a global online fashion retailer. CLTV prediction is an important problem in e-commerce where an accurate estimate of future value allows retailers to effectively allocate marketing spend, identify and nurture high value customers and mitigate exposure to losses. The system at ASOS provides daily estimates of the future value of every customer and is one of the cornerstones of the personalised shopping experience. The state of the art in this domain uses large numbers of handcrafted features and ensemble regressors to forecast value, predict churn and evaluate customer loyalty. Recently, domains including language, vision and speech have shown dramatic advances by replacing handcrafted features with features that are learned automatically from data. We detail the system deployed at ASOS and show that learning feature representations is a promising extension to the state of the art in CLTV modelling. We propose a novel way to generate embeddings of customers, which addresses the issue of the ever changing product catalogue and obtain a significant improvement over an exhaustive set of handcrafted features.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1753–1762},
numpages = {10},
keywords = {e-commerce, neural networks, embeddings, random forests, customer lifetime value},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/2818869.2818919,
author = {Lu, Xiao-Yong and Chu, Xiao-Qiang and Chen, Meng-Hui and Chang, Pei-Chann},
title = {Data Analytics for Bank Term Deposit by Combining Artificial Immune Network and Collaborative Filtering},
year = {2015},
isbn = {9781450337359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2818869.2818919},
doi = {10.1145/2818869.2818919},
abstract = {To predict the preference of customer is essential to every financial service company, and by developing a high-efficient classification model can make a company to increase their profit and reduce the cost. In marketing, the uses of big data include "recommendation engines" to make suggestions based on the prior interests of a customer as compared to others. Thus, the main idea of this research presents an artificial immune classification combining collaborative filtering approach for bank term deposit recommendation. Artificial Immune Network (AIN) is a network of customers with bank term deposit and it can be adopted as a group decision making model in predicting whether a new customer will have a term deposit or not. A series of experiments are conducted, and the results are very encouraging. In spite of the class imbalance problem in the test dataset, our proposed model outperformed other models with highest accuracy.},
booktitle = {Proceedings of the ASE BigData &amp; SocialInformatics 2015},
articleno = {19},
numpages = {6},
keywords = {Artificial Immune System, Recommendation System, Financial Product, Collaborative Filtering, Nature-Inspired Systems, Term Deposit, Big Data},
location = {Kaohsiung, Taiwan},
series = {ASE BD&amp;SI '15}
}

@inproceedings{10.1145/2908961.2927002,
author = {Zhang, Mengjie and Xue, Bing},
title = {Evolutionary Computation for Feature Selection and Feature Construction},
year = {2016},
isbn = {9781450343237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2908961.2927002},
doi = {10.1145/2908961.2927002},
booktitle = {Proceedings of the 2016 on Genetic and Evolutionary Computation Conference Companion},
pages = {861–881},
numpages = {21},
keywords = {feature construction, dimensionality reduction, feature extraction, feature selection},
location = {Denver, Colorado, USA},
series = {GECCO '16 Companion}
}

@inproceedings{10.1145/1871437.1871758,
author = {Pavlov, Dmitry Yurievich and Gorodilov, Alexey and Brunk, Cliff A.},
title = {BagBoo: A Scalable Hybrid Bagging-the-Boosting Model},
year = {2010},
isbn = {9781450300995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1871437.1871758},
doi = {10.1145/1871437.1871758},
abstract = {In this paper, we introduce a novel machine learning approach for regression based on the idea of combining bagging and boosting that we call BagBoo. Our BagBoo model borrows its high accuracy potential from. Friedman's gradient boosting [2], and high efficiency and scalability through parallelism from Breiman's bagging [1]. We run empirical evaluations on large scale Web ranking data, and demonstrate that BagBoo is not only showing superior relevance than standalone bagging or boosting, but also outperforms most previously published results on these data sets. We also emphasize that BagBoo is intrinsically scalable and parallelizable, allowing us to train order of half a million trees on 200 nodes in 2 hours CPU time and beat all of the competitors in the Internet Mathematics relevance competition sponsored by Yandex and be one of the top algorithms in both tracks of Yahoo ICML-2010 challenge. We conclude the paper by stating that while impressive experimental evaluation results are presented here in the context of regression trees, the hybrid BagBoo model is applicable to other domains, such as classification, and base training models.},
booktitle = {Proceedings of the 19th ACM International Conference on Information and Knowledge Management},
pages = {1897–1900},
numpages = {4},
keywords = {ranking, boosting, bagging, learning to rank, experimentation, bagboo},
location = {Toronto, ON, Canada},
series = {CIKM '10}
}

@inproceedings{10.1145/3034950.3034985,
author = {Zhu, Jingwen and Xu, Jing and Zhang, Chao and Gao, Ya},
title = {Marine Fishing Ground Prediction Based on Bayesian Decision Tree Model},
year = {2017},
isbn = {9781450348348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3034950.3034985},
doi = {10.1145/3034950.3034985},
abstract = {The fisheries economy has become the focus of China's economic development in recent years. Improving the prediction accuracy of fishing ground is of great benefit to the growth of fisheries economy. Naive Bayes and decision tree algorithms are widely used due to their high classification performance and simplicity. Naive Bayes model has a stable classification efficiency and is less sensitive to missing data. J48 decision tree model has high accuracy, and the classification rules are easy to understand. However, both models have their own limitations in classification problems. Therefore, NBDT-J48 model based on Naive Bayes and J48 decision tree is designed in this paper. This model weakens the attribute independence assumption of Naive Bayes and makes up for the limitations of J48 decision tree in ignoring missing data. The experimental results show that the NBDT-J48 model achieves higher model accuracy than the other two models. Therefore, this model is suitable for the prediction of fishing ground. It has a good effect on handling data with missing attribute values and ambiguous relationship between attributes.},
booktitle = {Proceedings of the 2017 International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {316–320},
numpages = {5},
keywords = {Naive Bayes, J48 decision tree, Fishing ground prediction, Bayesian decision tree},
location = {Wuhan, China},
series = {ICMSS '17}
}

@inproceedings{10.1145/3299869.3319878,
author = {Li, Side and Chen, Lingjiao and Kumar, Arun},
title = {Enabling and Optimizing Non-Linear Feature Interactions in Factorized Linear Algebra},
year = {2019},
isbn = {9781450356435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299869.3319878},
doi = {10.1145/3299869.3319878},
abstract = {Accelerating machine learning (ML) over relational data is a key focus of the database community. While many real-world datasets are multi-table, most ML tools expect single-table inputs, forcing users to materialize joins before ML, leading to data redundancy and runtime waste. Recent works on ''factorized ML'' address such issues by pushing ML through joins. However, they have hitherto been restricted to ML models linear in the feature space, rendering them less effective when users construct non-linear feature interactions such as pairwise products to boost ML accuracy. In this work, we take a first step towards closing this gap by introducing a new abstraction to enable pairwise feature interactions in multi-table data and present an extensive framework of algebraic rewrite rules for factorized LA operators over feature interactions. Our rewrite rules carefully exploit the interplay of the redundancy caused by both joins and interactions. We prototype our framework in Python to build a tool we call MorpheusFI. An extensive empirical evaluation with both synthetic and real datasets shows that MorpheusFI yields up to 5x speedups over materialized execution for a popular second-order gradient method and even an order of magnitude speedups over a popular stochastic gradient method.},
booktitle = {Proceedings of the 2019 International Conference on Management of Data},
pages = {1571–1588},
numpages = {18},
keywords = {factorized ml, linear algebra, data management for ml, feature interactions},
location = {Amsterdam, Netherlands},
series = {SIGMOD '19}
}

@inproceedings{10.1145/2808797.2808853,
author = {Teinemaa, Irene and Leontjeva, Anna and Dumas, Marlon and Kikas, Riivo},
title = {Community-Based Prediction of Activity Change in Skype},
year = {2015},
isbn = {9781450338547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808797.2808853},
doi = {10.1145/2808797.2808853},
abstract = {A key problem for facilitators of online communication and social networks is to identify users whose activity is likely to change in the near future. Such predictions may serve as basis for targeted campaigns aimed at sustaining or increasing overall user engagement in the network. A common approach to this problem is to apply machine learning methods to make predictions at the level of individuals. These approaches consider only information about each individual user and, thus, do not exploit the social connections and structure of the network. In this paper, we approach the problem of activity change prediction at the level of communities rather than individuals. We develop predictive models of activity change over communities obtained using state-of-art community detection methods and compare their predictive power with each other and against the single-user baseline and ego networks. The results show that community-level prediction models achieve higher prediction accuracy than the traditional single-user approach, whereas a local community detection algorithm outperforms a global modularity-based method.},
booktitle = {Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015},
pages = {73–80},
numpages = {8},
location = {Paris, France},
series = {ASONAM '15}
}

@article{10.1145/2590989.2590993,
author = {Bordawekar, Rajesh and Blainey, Bob and Apte, Chidanand},
title = {Analyzing Analytics},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0163-5808},
url = {https://doi.org/10.1145/2590989.2590993},
doi = {10.1145/2590989.2590993},
abstract = {Many organizations today are faced with the challenge of processing and distilling information from huge and growing collections of data. Such organizations are increasingly deploying sophisticated mathematical algorithms to model the behavior of their business processes to discover correlations in the data, to predict trends and ultimately drive decisions to optimize their operations. These techniques, are known collectively as analytics, and draw upon multiple disciplines, including statistics, quantitative analysis, data mining, and machine learning. In this survey paper, we identify some of the key techniques employed in analytics both to serve as an introduction for the non-specialist and to explore the opportunity for greater optimizations for parallelization and acceleration using commodity and specialized multi-core processors. We are interested in isolating and documenting repeated patterns in analytical algorithms, data structures and data types, and in understanding howthese could be most effectively mapped onto parallel infrastructure. To this end, we focus on analytical models that can be executed using different algorithms. For most major model types, we study implementations of key algorithms to determine common computational and runtime patterns. We then use this information to characterize and recommend suitable parallelization strategies for these algorithms, specifically when used in data management workloads.},
journal = {SIGMOD Rec.},
month = feb,
pages = {17–28},
numpages = {12}
}

@inproceedings{10.1145/3205651.3207862,
author = {Xue, Bing and Zhang, Mengjie},
title = {Evolutionary Computation for Feature Selection and Feature Construction},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3207862},
doi = {10.1145/3205651.3207862},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1198–1220},
numpages = {23},
location = {Kyoto, Japan},
series = {GECCO '18}
}

