@inproceedings{10.1145/3219819.3219821,
author = {Yang, Carl and Shi, Xiaolin and Jie, Luo and Han, Jiawei},
title = {I Know You'll Be Back: Interpretable New User Clustering and Churn Prediction on a Mobile Social Application},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219821},
doi = {10.1145/3219819.3219821},
abstract = {As online platforms are striving to get more users, a critical challenge is user churn, which is especially concerning for new users. In this paper, by taking the anonymous large-scale real-world data from Snapchat as an example, we develop ClusChurn , a systematic two-step framework for interpretable new user clustering and churn prediction, based on the intuition that proper user clustering can help understand and predict user churn. Therefore, ClusChurn firstly groups new users into interpretable typical clusters, based on their activities on the platform and ego-network structures. Then we design a novel deep learning pipeline based on LSTM and attention to accurately predict user churn with very limited initial behavior data, by leveraging the correlations among users' multi- dimensional activities and the underlying user types. ClusChurn is also able to predict user types, which enables rapid reactions to different types of user churn. Extensive data analysis and experiments show that ClusChurn provides valuable insight into user behaviors, and achieves state-of-the-art churn prediction performance. The whole framework is deployed as a data analysis pipeline, delivering real-time data analysis and prediction results to multiple relevant teams for business intelligence uses. It is also general enough to be readily adopted by any online systems with user behavior data.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {914–922},
numpages = {9},
keywords = {user clustering, interpretable model, churn prediction},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{10.1145/2939672.2939710,
author = {Khan, Muhammad R. and Blumenstock, Joshua E.},
title = {Predictors without Borders: Behavioral Modeling of Product Adoption in Three Developing Countries},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939710},
doi = {10.1145/2939672.2939710},
abstract = {Billions of people around the world live without access to banks or other formal financial institutions. In the past several years, many mobile operators have launched "Mobile Money" platforms that deliver basic financial services over the mobile phone network. While many believe that these services can improve the lives of the poor, in many countries adoption of Mobile Money still remains anemic. In this paper, we develop a predictive model of Mobile Money adoption that uses billions of mobile phone communications records to understand the behavioral determinants of adoption. We describe a novel approach to feature engineering that uses a Deterministic Finite Automaton to construct thousands of behavioral metrics of phone use from a concise set of recursive rules. These features provide the foundation for a predictive model that is tested on mobile phone operators logs from Ghana, Pakistan, and Zambia, three very different developing-country contexts. The results highlight the key correlates of Mobile Money use in each country, as well as the potential for such methods to predict and drive adoption. More generally, our analysis provides insight into the extent to which homogenized supervised learning methods can generalize across geographic contexts. We find that without careful tuning, a model that performs very well in one country frequently does not generalize to another.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {145–154},
numpages = {10},
keywords = {mobilemoney, gradient boosting, supervised learning, feature engineering, product adoption},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{10.1145/3328526.3329589,
author = {Agarwal, Anish and Dahleh, Munther and Sarkar, Tuhin},
title = {A Marketplace for Data: An Algorithmic Solution},
year = {2019},
isbn = {9781450367929},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328526.3329589},
doi = {10.1145/3328526.3329589},
abstract = {In this work, we aim to design a data marketplace; a robust real-time matching mechanism to efficiently buy and sell training data for Machine Learning tasks. While the monetization of data and pre-trained models is an essential focus of industry today, there does not exist a market mechanism to price training data and match buyers to sellers while still addressing the associated (computational and other) complexity. The challenge in creating such a market stems from the very nature of data as an asset: (i) it is freely replicable; (ii) its value is inherently combinatorial due to correlation with signal in other data; (iii) prediction tasks and the value of accuracy vary widely; (iv) usefulness of training data is difficult to verify a priori without first applying it to a prediction task. As our main contributions we: (i) propose a mathematical model for a two-sided data market and formally define the key associated challenges; (ii) construct algorithms for such a market to function and analyze how they meet the challenges defined. We highlight two technical contributions: (i) a new notion of "fairness" required for cooperative games with freely replicable goods; (ii) a truthful, zero regret mechanism to auction a class of combinatorial goods based on utilizing Myerson's payment function and the Multiplicative Weights algorithm. These might be of independent interest.},
booktitle = {Proceedings of the 2019 ACM Conference on Economics and Computation},
pages = {701–726},
numpages = {26},
keywords = {shapley value, value of data, data marketplaces, online combinatorial auctions},
location = {Phoenix, AZ, USA},
series = {EC '19}
}

@inproceedings{10.1145/3377929.3389857,
author = {Xue, Bing and Zhang, Mengjie},
title = {Evolutionary Computation for Feature Selection and Feature Construction},
year = {2020},
isbn = {9781450371278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377929.3389857},
doi = {10.1145/3377929.3389857},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion},
pages = {1283–1312},
numpages = {30},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@inproceedings{10.1145/3093742.3098278,
author = {Zapater, Sergi},
title = {The Customer Experience Case: The Needle in the Haystack},
year = {2017},
isbn = {9781450350655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3093742.3098278},
doi = {10.1145/3093742.3098278},
abstract = {Telecommunications usage is growing, with mobile broadband being at the forefront. Mobile operators need to cope with a massive amount of data to provide exceptional services and keep their end Subscribers. In this highly competitive context, Subscribers demand useful care services in real time.},
booktitle = {Proceedings of the 11th ACM International Conference on Distributed and Event-Based Systems},
pages = {5–6},
numpages = {2},
location = {Barcelona, Spain},
series = {DEBS '17}
}

@inproceedings{10.5555/1378245.1378248,
author = {Kolyshkina, Inna and Simoff, Simeon},
title = {Customer Analytics Projects: Addressing Existing Problems with a Process That Leads to Success},
year = {2007},
isbn = {9781920682514},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {This article explicitly outlines an approach designed to allow optimal utilisation of Analytics in the industry setting. The paper focuses on the key stages of the Analytics process that have not been identified in previous Analytics methodologies and draws on industry, consulting and research experience to show that correct design of the project trajectory can allow the industry to fully realise the benefits that Analytics has to offer. As the case studies provided demonstrate, it is often the skipping of key stages, especially the preliminary analysis stage, that are currently responsible for preventing success of an Analytics project. It has been shown how, using the outlined approach, project can achieve maximum effectiveness and business buy-in.},
booktitle = {Proceedings of the Sixth Australasian Conference on Data Mining and Analytics - Volume 70},
pages = {13–19},
numpages = {7},
keywords = {data mining effectiveness, industry analytics, analytics projects management, customer analytics, analytics industry case studies},
location = {Gold Coast, Australia},
series = {AusDM '07}
}

@inproceedings{10.1145/3154943.3154965,
author = {Wong, William Xiu Shun and Kim, Namgyu},
title = {Semi-Supervised Document Classification Using Heterogeneous Rule Selection},
year = {2017},
isbn = {9781450353120},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3154943.3154965},
doi = {10.1145/3154943.3154965},
abstract = {In traditional supervised classification, a large set of labeled data is required to train the model. However, labeled data are often hard to obtain and expensive, because human efforts are needed for the labeling. Therefore, semi-supervised learning techniques that utilize both labeled and unlabeled data together have gained much interest in the literature of data classification field. Among the semi-supervised learning techniques, self-training is one of the representative algorithms, which able to train a classifier iteratively by enlarging the learning set. Unfortunately, this iterative training process only works well if the predicted labels in high confidence are correct. To overcome this problem, we modify the self-training method of semi-supervised learning to improve the accuracy of document classification. In this work, we attempt to classify the source documents into different categories and measure their classification accuracy. We improve the self-training classifier in two ways. At first, we use heterogeneous unlabeled documents for enlarging original learning set. Next, in order to overcome the performance degradation problem of self-training, the rule selection algorithm is applied. Lastly, the classification accuracies of traditional supervised classification and our approach-integrated semi-supervised classification are compared.},
booktitle = {Proceedings of the International Conference on Electronic Commerce},
articleno = {17},
numpages = {3},
keywords = {semi-supervised learning, data mining, text mining, document classification},
location = {Pangyo, Seongnam, Republic of Korea},
series = {ICEC '17}
}

@inproceedings{10.1145/2701126.2701152,
author = {Hasim, Nurdatillah and Haris, Norhaidah Abu},
title = {A Study of Open-Source Data Mining Tools for Forecasting},
year = {2015},
isbn = {9781450333771},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701126.2701152},
doi = {10.1145/2701126.2701152},
abstract = {This paper described five open-sources Data Mining (DM) tools which are Weka, RapidMiner, KEEL, Orange and Tanagra. The features and functionality of these DM tools can be benefited by educators and researchers. The DM algorithms embedded in the tools can be utilized for forecasting. Weka and RapidMiner have most of the desire characteristic for a fully-functional and flexible platform therefore their use can be recommended for most of DM tasks.},
booktitle = {Proceedings of the 9th International Conference on Ubiquitous Information Management and Communication},
articleno = {79},
numpages = {4},
keywords = {tools, data mining, forecasting},
location = {Bali, Indonesia},
series = {IMCOM '15}
}

@inproceedings{10.1145/3167918.3167937,
author = {Demediuk, Simon and Murrin, Alexandra and Bulger, David and Hitchens, Michael and Drachen, Anders and Raffe, William L. and Tamassia, Marco},
title = {Player Retention in League of Legends: A Study Using Survival Analysis},
year = {2018},
isbn = {9781450354363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167918.3167937},
doi = {10.1145/3167918.3167937},
abstract = {Multi-player online esports games are designed for extended durations of play, requiring substantial experience to master. Furthermore, esports game revenues are increasingly driven by in-game purchases. For esports companies, the trends in players leaving their games therefore not only provide information about potential problems in the user experience, but also impacts revenue. Being able to predict when players are about to leave the game - churn prediction - is therefore an important solution for companies in the rapidly growing esports sector, as this allows them to take action to remedy churn problems.The objective of the work presented here is to understand the impact of specific behavioral characteristics on the likelihood of a player continuing to play the esports title League of Legends. Here, a solution to the problem is presented based on the application of survival analysis, using Mixed Effects Cox Regression, to predict player churn. Survival Analysis forms a useful approach for the churn prediction problem as it provides rates as well as an assessment of the characteristics of players who are at risk of leaving the game. Hazard rates are also presented for the leading indicators, with results showing that duration between matches played is a strong indicator of potential churn.},
booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
articleno = {43},
numpages = {9},
keywords = {business intelligence, prediction, esports, game analytics, churn, league of legends, churn prediction},
location = {Brisband, Queensland, Australia},
series = {ACSW '18}
}

@inproceedings{10.1145/3110025.3110132,
author = {Berengueres, Jose and Duran, Guillem and Castro, Dani},
title = {Happiness, an inside Job? Turnover Prediction Using Employee Likeability, Engagement and Relative Happiness},
year = {2017},
isbn = {9781450349932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3110025.3110132},
doi = {10.1145/3110025.3110132},
abstract = {In this paper, we describe how to rank employees for risk of turnover by using data obtained from a happiness self-reporting app. Two data sources are used: daily happiness and social interactions. The data spans 2.5 years and 4,356 employees of 34 companies based in Barcelona. For each employee, we build features at three levels: individual, company level and social interaction graph level. We develop various turnover risk models and we compare how different features affect performance prediction. The results show that the top three features that explain turnover risk are: ratio of likes received (likeability), posting frequency (engagement), and relative happiness (employee happiness normalized by company mean). Surprisingly, a priori expected explanatory features such as mean happiness level and the ratio of likes (positivity), were not significant. Precision@50 = 80% out of a test set with 116 churns, sample size N=2k.},
booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
pages = {509–516},
numpages = {8},
keywords = {Happiness, Privacy, Learning-to-Ranking, Information Retrieval},
location = {Sydney, Australia},
series = {ASONAM '17}
}

@article{10.1145/1376815.1376817,
author = {Gupta, Gunjan and Ghosh, Joydeep},
title = {Bregman Bubble Clustering: A Robust Framework for Mining Dense Clusters},
year = {2008},
issue_date = {July 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/1376815.1376817},
doi = {10.1145/1376815.1376817},
abstract = {In classical clustering, each data point is assigned to at least one cluster. However, in many applications only a small subset of the available data is relevant for the problem and the rest needs to be ignored in order to obtain good clusters. Certain nonparametric density-based clustering methods find the most relevant data as multiple dense regions, but such methods are generally limited to low-dimensional data and do not scale well to large, high-dimensional datasets. Also, they use a specific notion of “distance”, typically Euclidean or Mahalanobis distance, which further limits their applicability. On the other hand, the recent One Class Information Bottleneck (OC-IB) method is fast and works on a large class of distortion measures known as Bregman Divergences, but can only find a single dense region. This article presents a broad framework for finding k dense clusters while ignoring the rest of the data. It includes a seeding algorithm that can automatically determine a suitable value for k. When k is forced to 1, our method gives rise to an improved version of OC-IB with optimality guarantees. We provide a generative model that yields the proposed iterative algorithm for finding k dense regions as a special case. Our analysis reveals an interesting and novel connection between the problem of finding dense regions and exponential mixture models; a hard model corresponding to k exponential mixtures with a uniform background results in a set of k dense clusters. The proposed method describes a highly scalable algorithm for finding multiple dense regions that works with any Bregman Divergence, thus extending density based clustering to a variety of non-Euclidean problems not addressable by earlier methods. We present empirical results on three artificial, two microarray and one text dataset to show the relevance and effectiveness of our methods.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jul,
articleno = {8},
numpages = {49},
keywords = {exponential family, Bregman divergences, Density-based clustering, expectation maximization, One Class classification}
}

@inproceedings{10.1145/3368691.3368713,
author = {Mouchili, Mama Nsangou and Atwood, John William and Aljawarneh, Shadi},
title = {Call Data Record Based Big Data Analytics for Smart Cities},
year = {2019},
isbn = {9781450372848},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368691.3368713},
doi = {10.1145/3368691.3368713},
abstract = {A Call Data Record (CDR) is produced for each call (or other interaction) handled by a telephone company. CDRs have traditionally been used for billing and network engineering purposes. Given how mobile phones have become an integral part of - and have undoubtedly transformed - the everyday life of a great part of the earth's population, and given that 90% or more of phone subscriptions are registered in any city, if CDRs are collected from the mobile phone and cellular networks, and combined with other data from the organization or from elsewhere, this will allow managers to identify trends, detect patterns, and glean other valuable findings from the data.This paper highlights the applicability of CDR-based big data, to gathering such insights. By stitching events together into clusters of related events across runtime environments and/or geographies, raw data becomes business insight to make decisions either to understand customer needs, to mitigate problems, or to ultimately gain a competitive advantage.},
booktitle = {Proceedings of the Second International Conference on Data Science, E-Learning and Information Systems},
articleno = {22},
numpages = {7},
keywords = {random forest, big data, traffic congestion, insights, mining algorithms, city management, JSON, data analytics, traffic management, CDR, smart city, Hadoop},
location = {Dubai, United Arab Emirates},
series = {DATA '19}
}

@inproceedings{10.1109/WI-IAT.2013.186,
author = {Dey, Lipika and Verma, Ishan},
title = {Text-Driven Multi-Structured Data Analytics for Enterprise Intelligence},
year = {2013},
isbn = {9780769551456},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WI-IAT.2013.186},
doi = {10.1109/WI-IAT.2013.186},
abstract = {Text data constitutes the bulk of all enterprise data. Text repositories are not only tacit store-houses of knowledge about its people, projects and processes but also contain invaluable information about its customers, competitors, suppliers, partners and all other stakeholders. Mining this data can provide interesting and valuable insights provided it is appropriately integrated with other enterprise data. In this paper we propose a framework for text-driven analysis of multi-structured data.},
booktitle = {Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 03},
pages = {213–220},
numpages = {8},
keywords = {Text Analytics, Information Fusion},
series = {WI-IAT '13}
}

@inproceedings{10.1145/3312614.3312623,
author = {Khan, Nawsher and Naim, Arshi and Hussain, Mohammad Rashid and Naveed, Quadri Noorulhasan and Ahmad, Naim and Qamar, Shamimul},
title = {The 51 V's Of Big Data: Survey, Technologies, Characteristics, Opportunities, Issues and Challenges},
year = {2019},
isbn = {9781450366403},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3312614.3312623},
doi = {10.1145/3312614.3312623},
abstract = {Currently Big Data is the biggest buzzword, and definitely, we believe that Big Data is changing the world. Some researchers say Big Data will be even bigger buzzword than the Internet. With fast-growing computing resources, information and knowledge a new digital globe has emerged. Information is being created and stored at a fast rate and is being accessed by a vast range of applications through scientific computing, commercial workloads, and social media. In 2018, over 28 billion devices globally, are connected to the internet. In 2020, more than 50 billion smart appliances will be connected worldwide and internet traffic flow will be 92 times greater than it was in 2005. The usage of such a massive number of connected devices not only increase the data volume but also the velocity of data addition with speed of light on fiber optic and various wireless networks. This fast generation of enormous data creates numerous threats and challenges. There exist various approaches that are addressing issues and challenges of Big Data with the theory of Vs such as 3 V's, 5 V's, 7 V's etc. The objective of this work is to explore and investigate the status of the current Big Data domain. Further, a comprehensive overview of Big Data, its characteristics, opportunities, issues, and challenges have been explored and described with the help of 51 V's. The outcome of this research will help in understanding the Big Data in a systematic way.},
booktitle = {Proceedings of the International Conference on Omni-Layer Intelligent Systems},
pages = {19–24},
numpages = {6},
keywords = {data storage, Big Data, data generation, data characteristics},
location = {Crete, Greece},
series = {COINS '19}
}

@article{10.5555/3205191.3205200,
author = {Johnson, Jeremiah W.},
title = {Scaling up: Introducing Undergraduates to Data Science Early in Their College Careers},
year = {2018},
issue_date = {June 2018},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {33},
number = {6},
issn = {1937-4771},
abstract = {It has historically been the case that most data science and analytics programs are offered at the Master of Science level. What few undergraduate offerings exist are frequently limited to either a standalone course or a small number of courses targeted to upper level undergraduates. Literature on how best to teach data science to undergraduate students is practically nonexistent. We review recent work on establishing standards and learning objectives for undergraduate data science education, and we make the case that undergraduate students should be exposed to data science early in their college career. We describe the strategy used to teach an introductory course in data science aimed not at upper-level students, but at undergraduate students in their first or second year of study. This course assumes no prerequisite knowledge in computing, mathematics, or statistics, aligns well with recently outlined objectives for undergraduate data science education, and has a track record of success for five consecutive semesters.},
journal = {J. Comput. Sci. Coll.},
month = jun,
pages = {76–85},
numpages = {10}
}

@inproceedings{10.5555/2483628.2483643,
author = {Li, Fan and Lei, Juan and Tian, Ying and Punyapatthanakul, Sakuna and Wang, Yanbo J.},
title = {Model Selection Strategy for Customer Attrition Risk Prediction in Retail Banking},
year = {2011},
isbn = {9781921770029},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Nowadays customer attrition is increasingly serious in commercial banks, particularly, high-valued customers in retail banking. Hence, it is encouraged to develop a prediction mechanism and identify such customers who might be at risk of attrition. This prediction mechanism can be considered to be a classifier. In particular, the problem of predicting risk of customer attrition can be prototyped as a binary classification task in data mining. In previous studies, a number of techniques have been introduced in (binary) classification study, i. e. artificial-based model, Bayesian-based model, case-based model, tree-based model, regression-based model, rule-based model, etc. With regards to a particular application --- predicting customer attrition risk for retail banking, this paper presents four principles in (classification) model selection. To support this model selection study, a set of experiments were run, based on a collection of real customer data in retail banking. These results and consequent recommendations are given in this paper.},
booktitle = {Proceedings of the Ninth Australasian Data Mining Conference - Volume 121},
pages = {119–124},
numpages = {6},
keywords = {classification prediction, retail banking, model selection, customer attrition risk, commercial banks},
location = {Ballarat, Australia},
series = {AusDM '11}
}

@inproceedings{10.1145/2151677.2151680,
author = {ur Rehman Laghari, Khalil and Khan, Imran and Crespi, Noel},
title = {Quantitative and Qualitative Assessment of QoE for Multimedia Services in Wireless Environment},
year = {2012},
isbn = {9781450311663},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2151677.2151680},
doi = {10.1145/2151677.2151680},
abstract = {Quality of Experience (QoE) is emerging as the holy grail of human-centric multimedia services. QoE is a multi-disciplinary field based on social psychology, cognitive science, economics and engineering science, focused on understanding overall human quality of experience requirements. QoE has been viewed as the pivotal set of metrics in determining the success or failure of any product or service. In real time environment, QoE is influenced by multiple service factors such as application and network level QoS parameters, content, and business aspects. We emulate wireless environment and analyze the combined impact of the network and application level QoS parameters and content characteristics over user perceived quality for video streaming service. We use Rough Set Theory (RST) for quantitative assessment and simple CCA frame work for qualitative assessment of user data in order to understand the influence of multiple multimedia service parameters over QoE.},
booktitle = {Proceedings of the 4th Workshop on Mobile Video},
pages = {7–12},
numpages = {6},
keywords = {QoE, wireless, user experience, content, QoS, rough set theory, video streaming, qualitative assessment},
location = {Chapel Hill, North Carolina},
series = {MoVid '12}
}

@inproceedings{10.1145/2398776.2398833,
author = {Alcock, Shane and Nelson, Richard},
title = {Measuring the Impact of the Copyright Amendment Act on New Zealand Residential DSL Users},
year = {2012},
isbn = {9781450317054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2398776.2398833},
doi = {10.1145/2398776.2398833},
abstract = {The Copyright (Infringing File Sharing) Amendment Act 2011 (CAA) is a New Zealand law that aims to provide copyright holders with legal recourse when content is illegally shared over the Internet. This paper presents a study of residential DSL user behaviour using packet traces captured at a New Zealand ISP before, shortly after and several months after the CAA coming into effect. We use libprotoident to classify the observed traffic based on the application protocol being used to identify and examine any changes in traffic patterns that may be a result of the new law. We find that the use of peer-to-peer applications declined significantly once the CAA was in effect, suggesting a strong correlation. We also found that there were increases in tunneling, secure file transfer and remote access traffic amongst a small segment of the user population, which may indicate an increased uptake in the use of foreign seedboxes to bypass the jurisdiction of the CAA.},
booktitle = {Proceedings of the 2012 Internet Measurement Conference},
pages = {551–558},
numpages = {8},
keywords = {traffic classification, seedbox, residential dsl, p2p, internet law},
location = {Boston, Massachusetts, USA},
series = {IMC '12}
}

@inproceedings{10.1145/2593929.2593941,
author = {Anaya, Ivan Dario Paez and Simko, Viliam and Bourcier, Johann and Plouzeau, No\"{e}l and J\'{e}z\'{e}quel, Jean-Marc},
title = {A Prediction-Driven Adaptation Approach for Self-Adaptive Sensor Networks},
year = {2014},
isbn = {9781450328647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593929.2593941},
doi = {10.1145/2593929.2593941},
abstract = { Engineering self-adaptive software in unpredictable environments such as pervasive systems, where network's ability, remaining battery power and environmental conditions may vary over the lifetime of the system is a very challenging task. Many current software engineering approaches leverage run-time architectural models to ease the design of the autonomic control loop of these self-adaptive systems. While these approaches perform well in reacting to various evolutions of the runtime environment, implementations based on reactive paradigms have a limited ability to anticipate problems, leading to transient unavailability of the system, useless costly adaptations, or resources waste. In this paper, we follow a proactive self-adaptation approach that aims at overcoming the limitation of reactive approaches. Based on predictive analysis of internal and external context information, our approach regulates new architecture reconfigurations and deploys them using models at runtime. We have evaluated our approach on a case study where we combined hourly temperature readings provided by National Climatic Data Center (NCDC) with fire reports from Moderate Resolution Imaging Spectroradiometer (MODIS) and simulated the behavior of multiple systems. The results confirm that our proactive approach outperforms a typical reactive system in scenarios with seasonal behavior. },
booktitle = {Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {145–154},
numpages = {10},
keywords = {Self-adaptation, predictive analytics, pervasive systems, proactive adaptation},
location = {Hyderabad, India},
series = {SEAMS 2014}
}

@inproceedings{10.1145/2858036.2858464,
author = {Kim, Jooyeon and Keegan, Brian C. and Park, Sungjoon and Oh, Alice},
title = {The Proficiency-Congruency Dilemma: Virtual Team Design and Performance in Multiplayer Online Games},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858464},
doi = {10.1145/2858036.2858464},
abstract = {Multiplayer online battle arena games provide an excellent opportunity to study team performance. When designing a team, players must negotiate a proficiency-congruency dilemma between selecting roles that best match their experience and roles that best complement the existing roles on the team. We adopt a mixed-methods approach to explore how players negotiate this dilemma. Using data from League of Legends, we define a similarity space to operationalize team design constructs about role proficiency, generality, and congruency. We collect publicly available data from 3.36 million players to test the influence of these constructs on team performance. We also conduct focus groups with novice and elite players to understand how players' team design practices vary with expertise. We find that the two factors, player proficiency and team congruency, both increase team performance, with the former having a stronger impact. We also find that elite players are better at balancing the two factors than the novice players. These findings have implications for players, designers, and theorists about how to recommend team designs that jointly prioritize individuals' expertise and teams' compatibility.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4351–4365},
numpages = {15},
keywords = {computational social science, League of Legends, multiplayer online battle arena, team assembly, diversity, expertise},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/3041021.3055130,
author = {Lian, Jianxun and Zhang, Fuzheng and Xie, Xing and Sun, Guangzhong},
title = {Restaurant Survival Analysis with Heterogeneous Information},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055130},
doi = {10.1145/3041021.3055130},
abstract = {For shopkeepers, one of their biggest common concerns is whether their business will thrive or fail in the future. With the development of new ways to collect business data, it is possible to leverage multiple domains' knowledge to build an intelligent model for business assessment. In this paper, we discuss what the potential indicators are for the long-term survival of a physical store. To this end, we study factors from four pillars: geography, user mobility, user rating, and review text. We start by exploring the impact of geographic features, which describe the location environment of the retailer store. The location and nearby places play an important role in the popularity of the shop, and usually less competitiveness and more heterogeneity is better. Then we study user mobility. It can be viewed as supplementary to the geographical placement, showing how the location can attract users from anywhere. Another important factor is how the shop can serve and satisfy users. We find that restaurant survival prediction is a hard task that can not be solved simply using consumers' ratings or sentiment metrics. Compared with conclusive and well-formatted ratings, the various review words provide more insight of the shop and deserve in-depth mining. We adopt several language models to fully explore the textual message. Comprehensive experiments demonstrate that review text indeed have the strongest predictive power. We further compare different cities' models and find the conclusions are highly consistent. Although we focus on the class of restaurant in this paper, the method can be easily extended to other shop categories.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {993–1002},
numpages = {10},
keywords = {restaurant survival analysis, data mining, location-based services},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.5555/2330748.2330763,
author = {Huysegems, Raf and De Vleeschauwer, Bart and De Schepper, Koen and Hawinkel, Chris and Wu, Tingyao and Laevens, Koen and Van Leekwijck, Werner},
title = {Session Reconstruction for HTTP Adaptive Streaming: Laying the Foundation for Network-Based QoE Monitoring},
year = {2012},
isbn = {9781467312981},
publisher = {IEEE Press},
abstract = {HTTP Adaptive Streaming (HAS) is rapidly becoming a key video delivery technology for fixed and mobile networks. However, today there is no solution that allows network operators or CDN providers to perform network-based QoE monitoring for HAS sessions. We present a HAS QoE monitoring system, based on data collected in the network, without monitoring information from the client. To retrieve the major QoE parameters such as average quality, quality variation, rebuffering events and interactivity delay, we propose a technique called session reconstruction. We define a number of iterative steps and developed algorithms that can be used to perform HAS session reconstruction. Finally, we present the results of a working prototype for the reconstruction and monitoring of Microsoft Smooth Streaming HAS sessions that is capable of dealing with intermediate caching and user interactivity. We describe the main observations when using the platform to analyze more than a hundred HAS sessions.},
booktitle = {Proceedings of the 2012 IEEE 20th International Workshop on Quality of Service},
articleno = {15},
numpages = {9},
keywords = {HTTP streaming, adaptive streaming, QoE, quality monitoring},
location = {Coimbra, Portugal},
series = {IWQoS '12}
}

@article{10.1145/3370082,
author = {Jannach, Dietmar and Jugovac, Michael},
title = {Measuring the Business Value of Recommender Systems},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {2158-656X},
url = {https://doi.org/10.1145/3370082},
doi = {10.1145/3370082},
abstract = {Recommender Systems are nowadays successfully used by all major web sites—from e-commerce to social media—to filter content and make suggestions in a personalized way. Academic research largely focuses on the value of recommenders for consumers, e.g., in terms of reduced information overload. To what extent and in which ways recommender systems create business value is, however, much less clear, and the literature on the topic is scattered. In this research commentary, we review existing publications on field tests of recommender systems and report which business-related performance measures were used in such real-world deployments. We summarize common challenges of measuring the business value in practice and critically discuss the value of algorithmic improvements and offline experiments as commonly done in academic environments. Overall, our review indicates that various open questions remain both regarding the realistic quantification of the business effects of recommenders and the performance assessment of recommendation algorithms in&nbsp;academia.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = dec,
articleno = {16},
numpages = {23},
keywords = {survey, field tests, business value, Recommendation}
}

@article{10.14778/2733004.2733013,
author = {Simmen, David and Schnaitter, Karl and Davis, Jeff and He, Yingjie and Lohariwala, Sangeet and Mysore, Ajay and Shenoi, Vinayak and Tan, Mingfeng and Xiao, Yu},
title = {Large-Scale Graph Analytics in Aster 6: Bringing Context to Big Data Discovery},
year = {2014},
issue_date = {August 2014},
publisher = {VLDB Endowment},
volume = {7},
number = {13},
issn = {2150-8097},
url = {https://doi.org/10.14778/2733004.2733013},
doi = {10.14778/2733004.2733013},
abstract = {Graph analytics is an important big data discovery technique. Applications include identifying influential employees for retention, detecting fraud in a complex interaction network, and determining product affinities by exploiting community buying patterns. Specialized platforms have emerged to satisfy the unique processing requirements of large-scale graph analytics; however, these platforms do not enable graph analytics to be combined with other analytics techniques, nor do they work well with the vast ecosystem of SQL-based business applications.Teradata Aster 6.0 adds support for large-scale graph analytics to its repertoire of analytics capabilities. The solution extends the multi-engine processing architecture with support for bulk synchronous parallel execution, and a specialized graph engine that enables iterative analysis of graph structures. Graph analytics functions written to the vertex-oriented API exposed by the graph engine can be invoked from the context of an SQL query and composed with existing SQL-MR functions, thereby enabling data scientists and business applications to express computations that combine large-scale graph analytics with techniques better suited to a different style of processing. The solution includes a suite of pre-built graph analytic functions adapted for parallel execution.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {1405–1416},
numpages = {12}
}

@inproceedings{10.1145/2983323.2983787,
author = {Ji, Wendi and Wang, Xiaoling and Zhang, Dell},
title = {A Probabilistic Multi-Touch Attribution Model for Online Advertising},
year = {2016},
isbn = {9781450340731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983323.2983787},
doi = {10.1145/2983323.2983787},
abstract = {It is an important problem in computational advertising to study the effects of different advertising channels upon user conversions, as advertisers can use the discoveries to plan or optimize advertising campaigns. In this paper, we propose a novel Probabilistic Multi-Touch Attribution (PMTA) model which takes into account not only which ads have been viewed or clicked by the user but also when each such interaction occurred. Borrowing the techniques from survival analysis, we use the Weibull distribution to describe the observed conversion delay and use the hazard rate of conversion to measure the influence of an ad exposure. It has been shown by extensive experiments on a large real-world dataset that our proposed model is superior to state-of-the-art methods in both conversion prediction and attribution analysis. Furthermore, a surprising research finding obtained from this dataset is that search ads are often not the root cause of final conversions but just the consequence of previously viewed ads.},
booktitle = {Proceedings of the 25th ACM International on Conference on Information and Knowledge Management},
pages = {1373–1382},
numpages = {10},
keywords = {multi-touch attribution, computational advertising, survival analysis},
location = {Indianapolis, Indiana, USA},
series = {CIKM '16}
}

@article{10.1145/3158421.3158424,
author = {Lee, Hanjun and Jeong, Suyeon and Suh, Yongmoo},
title = {The Influence of Negative Emotions on Customer Innovation Activities: An Examination Using Sentiment Analysis},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0095-0033},
url = {https://doi.org/10.1145/3158421.3158424},
doi = {10.1145/3158421.3158424},
abstract = {With the advent of Web 2.0, increased user participation in diverse e-communities resulted in an abundance of information, including emotional information. We examined the influence of negative emotion in an online brand community, MyStarbuckIdea.com, developed to collect diverse customer ideas for the firm?s innovation, with the purpose of investigating how such emotion affects customer activities for innovation in the community. We first established several hypotheses on the relationships between discrete negative emotions and innovation activities. Then, having collected 84,918 customer ideas, we conducted POS tagging and term-based matching to calculate the inclusion and intensity of negative emotion using the negative emotion lexicon which we developed. As a result of testing our hypotheses with regression models, we show that 1) negative emotion significantly affects innovation activities in the brand community, and frustration is the most influential among the discrete negative emotions; and 2) as the intensity level of negative emotions increases, so does their influence.},
journal = {SIGMIS Database},
month = nov,
pages = {14–29},
numpages = {16},
keywords = {sentiment analysis, brand community, mystarbucksidea.com, negative emotion, text mining, open innovation}
}

@inproceedings{10.1145/1557019.1557136,
author = {Bhattacharya, Indrajit and Godbole, Shantanu and Gupta, Ajay and Verma, Ashish and Achtermann, Jeff and English, Kevin},
title = {Enabling Analysts in Managed Services for CRM Analytics},
year = {2009},
isbn = {9781605584959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1557019.1557136},
doi = {10.1145/1557019.1557136},
abstract = {Data analytics tools and frameworks abound, yet rapid deployment of analytics solutions that deliver actionable insights from business data remains a challenge. The primary reason is that on-field practitioners are required to be both technically proficient and knowledgeable about the business. The recent abundance of unstructured business data has thrown up new opportunities for analytics, but has also multiplied the deployment challenge, since interpretation of concepts derived from textual sources require a deep understanding of the business. In such a scenario, a managed service for analytics comes up as the best alternative. A managed analytics service is centered around a business analyst who acts as a liaison between the business and the technology. This calls for new tools that assist the analyst to be efficient in the tasks that she needs to execute. Also, the analytics needs to be repeatable, in that the delivered insights should not depend heavily on the expertise of specific analysts. These factors lead us to identify new areas that open up for KDD research in terms of 'time-to-insight' and repeatability for these analysts. We present our analytics framework in the form of a managed service offering for CRM analytics. We describe different analyst-centric tools using a case study from real-life engagements and demonstrate their effectiveness.},
booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1077–1086},
numpages = {10},
keywords = {text mining, analytics service},
location = {Paris, France},
series = {KDD '09}
}

@inproceedings{10.1145/2786451.2786455,
author = {Tinati, Ramine and Luczak-Roesch, Markus and Simperl, Elena and Shadbolt, Nigel and Hall, Wendy},
title = { '/Command' and Conquer: Analysing Discussion in a Citizen Science Game},
year = {2015},
isbn = {9781450336727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786451.2786455},
doi = {10.1145/2786451.2786455},
abstract = {Citizen science is changing the process of scientific knowledge discovery. Successful projects rely on an active and able collection of volunteers. In order to attract, and sustain citizen scientists, designers are faced with the task of transforming complex scientific tasks into something accessible, interesting, and hopefully, engaging. In this paper, we examine the citizen science game EyeWire. Our analysis draws up a dataset of over 4,000,000 completed game and 885,000 chat entries, made by over 90,000 players. The analysis provides a detailed understanding of how features of the system facilitate player interaction and communication alongside completing the gamified scientific task. Based on the analysis we describe a set of behavioural characteristics which identify different types of players within the EyeWire platform.},
booktitle = {Proceedings of the ACM Web Science Conference},
articleno = {26},
numpages = {10},
keywords = {Gamification, Online Communities, Citizen Science, Player Behaviour},
location = {Oxford, United Kingdom},
series = {WebSci '15}
}

@proceedings{10.1145/2723372,
title = {SIGMOD '15: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to SIGMOD 2015 -- officially, the 2015 ACM SIGMOD International Conference on the Management of Data! This year's conference is being held in the beautiful cultural capital of Australia, Melbourne. During the Gold Rush period of the 19th Century, Melbourne was the richest city in the world, and as a result it is filled with many unique neighborhoods and distinctive buildings. In addition to wonderful neighborhoods to explore, the city has great museums and other cultural attractions, as well as a fine multi-cultural atmosphere. For those who would like to explore the outdoors, popular highlights are the Phillip Island Nature Park (90 minutes away), which features wild penguins who return in a parade each day at sunset, and the Great Ocean Road, one of the world's most scenic coastal drives, including the famous towering 12 Apostles.SIGMOD 2015's exciting technical program reflects not only traditional topics, but the database community's role in broader data science and data analytics. The keynote from Laura Haas, "The Power Behind the Throne: Information Integration in the Age of Data-Driven Discovery" highlights the role of database and data integration techniques in the growing field of data science. Jignesh Patel's talk, "From Data to Insights @ Bare Metal Speed," explains how hardware and software need to be co-evolved to support the needs of scalable data analytics. Jennifer Widom, winner of the 2015 ACM-W Athena Lecturer Award for fundamental contributions to computer science, will give her award talk, "Three Favorite Results," on Tuesday. Christopher R\'{e} will lead a panel on "Machine Learning and Databases: The Sound of Things to Come or a Cacophony of Hype?," with participants Divyakant Agrawal, Magdalena Balazinska, Michael Cafarella, Michael Jordan, Tim Kraska, and Raghu Ramakrishnan. Of course, there are also 106 research paper presentations, 4 tutorials, 30 demonstrations, and 18 industrial papers. Papers will be presented both as talks during the research sessions, and as part of plenary Poster Sessions.SIGMOD 2015 is preceded by the PhD Workshop, as well as workshops on leading-edge topics like data analytics (DanaC), databases and the Web (WebDB), exploratory search (ExploreDB), managing and mining spatial data (GeoRich), and graph data (GRADES); the New Researcher Symposium will take place on Wednesday. The banquet will be held in a Melbourne landmark, the Town Hall.As in recent years, we had two submission deadlines for SIGMOD this year, one in August and one in November. The review process was journal-style, with multiple rounds of reviews coordinated by the Group Leaders. We accepted 34 of 137 papers from the first deadline and 72 of 278 from the second deadline. The total acceptance rate was about 25.5%, and we believe that the revision processhas improved the quality of the technical program.},
location = {Melbourne, Victoria, Australia}
}

@article{10.1145/3185045,
author = {Zimbra, David and Abbasi, Ahmed and Zeng, Daniel and Chen, Hsinchun},
title = {The State-of-the-Art in Twitter Sentiment Analysis: A Review and Benchmark Evaluation},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {2158-656X},
url = {https://doi.org/10.1145/3185045},
doi = {10.1145/3185045},
abstract = {Twitter has emerged as a major social media platform and generated great interest from sentiment analysis researchers. Despite this attention, state-of-the-art Twitter sentiment analysis approaches perform relatively poorly with reported classification accuracies often below 70%, adversely impacting applications of the derived sentiment information. In this research, we investigate the unique challenges presented by Twitter sentiment analysis and review the literature to determine how the devised approaches have addressed these challenges. To assess the state-of-the-art in Twitter sentiment analysis, we conduct a benchmark evaluation of 28 top academic and commercial systems in tweet sentiment classification across five distinctive data sets. We perform an error analysis to uncover the causes of commonly occurring classification errors. To further the evaluation, we apply select systems in an event detection case study. Finally, we summarize the key trends and takeaways from the review and benchmark evaluation and provide suggestions to guide the design of the next generation of approaches.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = aug,
articleno = {5},
numpages = {29},
keywords = {social media, Sentiment analysis, benchmark evaluation, natural language processing, text mining, opinion mining, twitter}
}

@inproceedings{10.1145/2723372.2742794,
author = {Huang, Yiqing and Zhu, Fangzhou and Yuan, Mingxuan and Deng, Ke and Li, Yanhua and Ni, Bing and Dai, Wenyuan and Yang, Qiang and Zeng, Jia},
title = {Telco Churn Prediction with Big Data},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723372.2742794},
doi = {10.1145/2723372.2742794},
abstract = {We show that telco big data can make churn prediction much more easier from the $3$V's perspectives: Volume, Variety, Velocity. Experimental results confirm that the prediction performance has been significantly improved by using a large volume of training data, a large variety of features from both business support systems (BSS) and operations support systems (OSS), and a high velocity of processing new coming data. We have deployed this churn prediction system in one of the biggest mobile operators in China. From millions of active customers, this system can provide a list of prepaid customers who are most likely to churn in the next month, having $0.96$ precision for the top $50000$ predicted churners in the list. Automatic matching retention campaigns with the targeted potential churners significantly boost their recharge rates, leading to a big business value.},
booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
pages = {607–618},
numpages = {12},
keywords = {big data, telco churn prediction, customer retention},
location = {Melbourne, Victoria, Australia},
series = {SIGMOD '15}
}

@inproceedings{10.1145/2487575.2487590,
author = {Nagano, Shouichi and Ichikawa, Yusuke and Takaya, Noriko and Uchiyama, Tadasu and Abe, Makoto},
title = {Nonparametric Hierarchal Bayesian Modeling in Non-Contractual Heterogeneous Survival Data},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487590},
doi = {10.1145/2487575.2487590},
abstract = {An important problem in the non-contractual marketing domain is discovering the customer lifetime and assessing the impact of customer's characteristic variables on the lifetime. Unfortunately, the conventional hierarchical Bayes model cannot discern the impact of customer's characteristic variables for each customer. To overcome this problem, we present a new survival model using a non-parametric Bayes paradigm with MCMC. The assumption of a conventional model, logarithm of purchase rate and dropout rate with linear regression, is extended to include our assumption of the Dirichlet Process Mixture of regression. The extension assumes that each customer belongs probabilistically to different mixtures of regression, thereby permitting us to estimate a different impact of customer characteristic variables for each customer. Our model creates several customer groups to mirror the structure of the target data set.The effectiveness of our proposal is confirmed by a comparison involving a real e-commerce transaction dataset and an artificial dataset; it generally achieves higher predictive performance. In addition, we show that preselecting the actual number of customer groups does not always lead to higher predictive performance.},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {668–676},
numpages = {9},
keywords = {non-parametric bayes, model choice, crm, mcmc},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@article{10.1109/TNET.2018.2854795,
author = {Liu, Zhuotao and Jin, Hao and Hu, Yih-Chun and Bailey, Michael},
title = {Practical Proactive DDoS-Attack Mitigation via Endpoint-Driven In-Network Traffic Control},
year = {2018},
issue_date = {August 2018},
publisher = {IEEE Press},
volume = {26},
number = {4},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2018.2854795},
doi = {10.1109/TNET.2018.2854795},
abstract = {Volumetric attacks, which overwhelm the bandwidth of a destination, are among the most common distributed denial-of-service DDoS attacks today. Despite considerable effort made by both research and industry, our recent interviews with over 100 potential DDoS victims in over 10 industry segments indicate that today’s DDoS prevention is far from perfect. On one hand, few academical proposals have ever been deployed in the Internet; on the other hand, solutions offered by existing DDoS prevention vendors are not silver bullet to defend against the entire attack spectrum. Guided by such large-scale study of today’s DDoS defense, in this paper, we present MiddlePolice, the first readily deployable and proactive DDoS prevention mechanism. We carefully architect MiddlePolice such that it requires no changes from both the Internet core and the network stack of clients, yielding instant deployability in the current Internet architecture. Further, relying on our novel capability feedback mechanism, MiddlePolice is able to enforce destination-driven traffic control so that it guarantees to deliver victim-desired traffic regardless of the attacker strategies. We implement a prototype of MiddlePolice and demonstrate its feasibility via extensive evaluations in the Internet, hardware testbed, and large-scale simulations.},
journal = {IEEE/ACM Trans. Netw.},
month = aug,
pages = {1948–1961},
numpages = {14}
}

@inproceedings{10.1145/2335484.2335519,
author = {Paschke, Adrian and Vincent, Paul and Alves, Alex and Moxey, Catherine},
title = {Tutorial on Advanced Design Patterns in Event Processing},
year = {2012},
isbn = {9781450313155},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2335484.2335519},
doi = {10.1145/2335484.2335519},
abstract = {We introduce a reference architecture for event processing, as defined by the EPTS reference architecture (RA) working group. An event processing reference architecture allows users to quickly create event processing solutions that adhere to known stakeholder requirements and architectural qualities. The focus in this paper is on the EPTS reference architecture description of the functional view which is supported by a mapping of its functions into design patterns as means to derive and prove these architectural descriptions to be usable solutions for recurring best practice implementations in common CEP languages.},
booktitle = {Proceedings of the 6th ACM International Conference on Distributed Event-Based Systems},
pages = {324–334},
numpages = {11},
keywords = {design patterns, complex event processing, reference architecture},
location = {Berlin, Germany},
series = {DEBS '12}
}

@article{10.1145/2893487,
author = {Palaghias, Niklas and Hoseinitabatabaei, Seyed Amir and Nati, Michele and Gluhak, Alexander and Moessner, Klaus},
title = {A Survey on Mobile Social Signal Processing},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2893487},
doi = {10.1145/2893487},
abstract = {Understanding human behavior in an automatic but nonintrusive manner is an important area for various applications. This requires the collaboration of information technology with human sciences to transfer existing knowledge of human behavior into self-acting tools. These tools will reduce human error that is introduced by current obtrusive methods such as questionnaires. To achieve unobtrusiveness, we focus on exploiting the pervasive and ubiquitous character of mobile devices.In this article, a survey of existing techniques for extracting social behavior through mobile devices is provided. Initially, we expose the terminology used in the area and introduce a concrete architecture for social signal processing applications on mobile phones, constituted by sensing, social interaction detection, behavioral cues extraction, social signal inference, and social behavior understanding. Furthermore, we present state-of-the-art techniques applied to each stage of the process. Finally, potential applications are shown while arguing about the main challenges of the area.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {57},
numpages = {52},
keywords = {Social signal processing, mobile phones, social behavior}
}

@article{10.1145/1961189.1961194,
author = {Bonchi, Francesco and Castillo, Carlos and Gionis, Aristides and Jaimes, Alejandro},
title = {Social Network Analysis and Mining for Business Applications},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/1961189.1961194},
doi = {10.1145/1961189.1961194},
abstract = {Social network analysis has gained significant attention in recent years, largely due to the success of online social networking and media-sharing sites, and the consequent availability of a wealth of social network data. In spite of the growing interest, however, there is little understanding of the potential business applications of mining social networks. While there is a large body of research on different problems and methods for social network mining, there is a gap between the techniques developed by the research community and their deployment in real-world applications. Therefore the potential business impact of these techniques is still largely unexplored.In this article we use a business process classification framework to put the research topics in a business context and provide an overview of what we consider key problems and techniques in social network analysis and mining from the perspective of business applications. In particular, we discuss data acquisition and preparation, trust, expertise, community structure, network dynamics, and information propagation. In each case we present a brief overview of the problem, describe state-of-the art approaches, discuss business application examples, and map each of the topics to a business process classification framework. In addition, we provide insights on prospective business applications, challenges, and future research directions. The main contribution of this article is to provide a state-of-the-art overview of current techniques while providing a critical perspective on business applications of social network analysis and mining.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {22},
numpages = {37},
keywords = {influence propagation, community structure, Social networks, viral marketing, networks dynamics and evolution, expert finding}
}

